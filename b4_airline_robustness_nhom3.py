# -*- coding: utf-8 -*-
"""B4. Airline-Robustness-Nhom3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1VUoMzwePsA0FIUROQUNIHgfPo-WCErim

# Prepare Data
"""

from pathlib import Path

# === Paths ===
DATA_DIR = Path("./data")
OUT_DIR  = Path("./outputs")
OUT_DIR.mkdir(parents=True, exist_ok=True)

AIRPORTS   = DATA_DIR / "airports.dat"
AIRLINES   = DATA_DIR / "airlines.dat"
ROUTES     = DATA_DIR / "routes.dat"
PLANES     = DATA_DIR / "planes.dat"
COUNTRIES  = DATA_DIR / "countries.dat"

print("Files present:",
      AIRPORTS.exists(), AIRLINES.exists(), ROUTES.exists(), PLANES.exists(), COUNTRIES.exists())

import numpy as np, pandas as pd, networkx as nx, matplotlib.pyplot as plt

plt.rcParams.update({"figure.dpi": 130})

AIRPORTS_COLS = ["airport_id","name","city","country","iata","icao","lat","lon","altitude","timezone","dst","tz_db","type","source"]
AIRLINES_COLS = ["airline_id","name","alias","iata","icao","callsign","country","active"]
ROUTES_COLS   = ["airline_code","airline_id","src_code","src_id","dst_code","dst_id","codeshare","stops","equipment"]
PLANES_COLS   = ["name","iata_code","icao_code"]
COUNTRIES_COLS= ["name","iso_code","dafif_code"]

def load_all(airports, airlines, routes, planes, countries):
    ap = pd.read_csv(airports, header=None, names=AIRPORTS_COLS, na_values=["\\N"])
    al = pd.read_csv(airlines, header=None, names=AIRLINES_COLS, na_values=["\\N"])
    rt = pd.read_csv(routes,   header=None, names=ROUTES_COLS,   na_values=["\\N"])
    pl = pd.read_csv(planes,   header=None, names=PLANES_COLS,   na_values=["\\N"])
    co = pd.read_csv(countries, header=None, names=COUNTRIES_COLS, na_values=["\\N"])


    ap = ap.dropna(subset=["airport_id"])
    ap["airport_id"] = ap["airport_id"].astype(int)
    ap["iata"] = ap["iata"].astype(str).str.strip().str.upper()
    ap["icao"] = ap["icao"].astype(str).str.strip().str.upper()
    ap["country"] = ap["country"].astype(str).str.strip()

    # airlines
    al["airline_id"] = pd.to_numeric(al["airline_id"], errors="coerce")
    al = al.dropna(subset=["airline_id"])
    al["airline_id"] = al["airline_id"].astype(int)
    al["iata"] = al["iata"].astype(str).str.strip().str.upper()
    al["icao"] = al["icao"].astype(str).str.strip().str.upper()

    # routes
    rt["src_id"] = pd.to_numeric(rt["src_id"], errors="coerce")
    rt["dst_id"] = pd.to_numeric(rt["dst_id"], errors="coerce")
    rt = rt.dropna(subset=["src_id","dst_id"])
    rt["src_id"] = rt["src_id"].astype(int)
    rt["dst_id"] = rt["dst_id"].astype(int)
    rt["equipment"] = rt["equipment"].fillna("").astype(str).str.strip()

    # planes
    pl["iata_code"] = pl["iata_code"].astype(str).str.strip().str.upper()
    pl["icao_code"] = pl["icao_code"].astype(str).str.strip().str.upper()
    pl["name"] = pl["name"].astype(str).str.strip()

    # countries
    co["name"] = co["name"].astype(str).str.strip()

    return ap, al, rt, pl, co

ap, al, rt, pl, co = load_all(AIRPORTS, AIRLINES, ROUTES, PLANES, COUNTRIES)
ap.shape, al.shape, rt.shape, pl.shape, co.shape

print("Airports NA summary:\n", ap.isna().sum(), "\n")
print("Airlines NA summary:\n", al.isna().sum(), "\n")
print("Routes NA summary:\n", rt.isna().sum(), "\n")

print("Sample airports:\n", ap.head(3), "\n")
print("Sample airlines:\n", al.head(3), "\n")
print("Sample routes:\n", rt.head(3))

"""# Analysis on Directed Graph

## Build Graph
"""

import networkx as nx
import pandas as pd

def build_directed_graph(ap, rt):

    valid = set(ap["airport_id"])

    # Lọc routes hợp lệ
    r = rt[(rt["src_id"].isin(valid)) & (rt["dst_id"].isin(valid))]
    # - Loại bỏ self-loops (bay tại chỗ A -> A)
    r = r[r["src_id"] != r["dst_id"]].copy()

    # Xây dựng đồ thị ban đầu
    G = nx.DiGraph()
    G.add_nodes_from(ap["airport_id"].tolist())
    G.add_edges_from(zip(r["src_id"], r["dst_id"]))

    # Gán thuộc tính cho node
    attrs = ap.set_index("airport_id")[["name","city","country","iata","icao","lat","lon"]].to_dict("index")
    nx.set_node_attributes(G, attrs)

    print(f"Số node ban đầu (Directed): {G.number_of_nodes()}")
    print(f"Số cạnh ban đầu (Directed): {G.number_of_edges()}")

    # --- LỌC DỰA TRÊN STRONGLY CONNECTED COMPONENT (SCC) ---

    # Tìm tập hợp các nodes thuộc SCC lớn nhất
    # SCC: Mọi node trong tập hợp đều có đường đi đến mọi node khác (A->B và B->A, có thể qua trung gian)
    if G.number_of_nodes() > 0:
        largest_scc_nodes = max(nx.strongly_connected_components(G), key=len)

        # Tạo subgraph từ SCC lớn nhất
        G_scc_clean = G.subgraph(largest_scc_nodes).copy()

        # Cập nhật lại G
        G = G_scc_clean
    else:
        # Trường hợp đồ thị rỗng (hiếm gặp với data OpenFlights)
        print("Cảnh báo: Đồ thị rỗng!")

    return G, r

# --- SỬ DỤNG ---
# Giả sử bạn đã load data vào biến ap (airports) và rt (routes)
G_di, r_clean_di = build_directed_graph(ap, rt)

print(f"Số node sau khi lọc (SCC): {G_di.number_of_nodes()}")
print(f"Số cạnh sau khi lọc: {G_di.number_of_edges()}")

"""## Metrics"""

!pip install networkit

from networkx.algorithms import approximation as apx
import networkit as nk
from math import inf
import random
import networkx as nx
import numpy as np
import pandas as pd
from IPython.display import display

def scc_nodes(G):
    """Trả về tập node của Strongly connected component lớn nhất"""
    if not isinstance(G, nx.DiGraph):
        raise TypeError("scc_nodes() chỉ dùng cho DiGraph.")
    if G.number_of_nodes() == 0:
        return set()
    try:
        return max(nx.strongly_connected_components(G), key=len)
    except ValueError:
        return set()

def scc_fraction(G, N0):
    """Tính tỉ lệ SCC lớn nhất so với N0 ban đầu"""
    if N0 <= 0 or G.number_of_nodes() == 0:
        return 0.0
    return len(scc_nodes(G)) / float(N0)

def R_index(fracs, curve):
    """Tính diện tích dưới robustness curve (Area Under Curve)"""
    return float(np.trapezoid(curve, fracs))


def get_lscc_nk(G):
    """
    Lấy LSCC (Largest Strongly Connected Component) và convert sang NetworKit.
    """
    if G.number_of_nodes() <= 1:
        return None, 0

    try:
        sccs = list(nx.strongly_connected_components(G))
        if not sccs:
            return None, 0

        largest_scc = max(sccs, key=len)

        if len(largest_scc) <= 1:
            return None, 0

        # Tạo subgraph
        S_nx = G.subgraph(largest_scc)
        nodes_list = list(S_nx.nodes())
        node_map = {n: i for i, n in enumerate(nodes_list)}
        n_count = len(nodes_list)

        # Convert sang NetworKit
        S_nk = nk.Graph(n_count, weighted=False, directed=True)

        for u, v in S_nx.edges():
            if u in node_map and v in node_map:
                S_nk.addEdge(node_map[u], node_map[v])

        return S_nk, n_count

    except:
        return None, 0


def compute_metrics_fastest(G):
    """
    Tính Diameter và APL trên LSCC (Strongly Connected Component).
    Returns:
        (diameter, apl) tuple
    """
    S_nk, n_count = get_lscc_nk(G)

    if S_nk is None or n_count == 0:
        return 0.0, 0.0

    try:
        max_diameter = 0
        total_distance = 0
        pair_count = 0

        # Chạy BFS từ TẤT CẢ các node
        for src in range(n_count):
            bfs = nk.distance.BFS(S_nk, src, storePaths=False)
            bfs.run()
            distances = bfs.getDistances()

            # Lọc khoảng cách hợp lệ (bỏ 0 và vô cùng)
            valid_dists = [d for d in distances if 0 < d < 1e9]

            if valid_dists:
                # Cập nhật diameter
                local_max = max(valid_dists)
                if local_max > max_diameter:
                    max_diameter = local_max

                # Cộng dồn cho APL
                total_distance += sum(valid_dists)
                pair_count += len(valid_dists)

        apl = (total_distance / pair_count) if pair_count > 0 else 0.0

        return float(max_diameter), float(apl)

    except:
        return 0.0, 0.0

"""## Configuration Experiment"""

# Configure experiment
FRACS = np.linspace(0, 1, 51) # 0%..100%
TRIALS = 20
ATTACK_MODE = "static"

"""### Consolidated Plotting"""

def plot_robustness_curves(title, ylabel, rand_curve, targ_degree_curve, targ_pagerank_curve, targ_betweenness_curve, filename):
    plt.figure(figsize=(8,5))
    plt.plot(FRACS*100, rand_curve, label=f"Random (trials={TRIALS})")
    plt.plot(FRACS*100, targ_degree_curve, label=f"Targeted-degree ({ATTACK_MODE})")
    plt.plot(FRACS*100, targ_pagerank_curve, label=f"Targeted-PageRank ({ATTACK_MODE})")
    plt.plot(FRACS*100, targ_betweenness_curve, label=f"Targeted-Betweenness ({ATTACK_MODE})")
    plt.xlabel("Fraction of airports removed (%)")
    plt.ylabel(ylabel)
    plt.title(title)
    plt.legend(); plt.tight_layout()
    plt.savefig(OUT_DIR/filename)
    print(OUT_DIR/filename)

"""## Attack method"""

def compute_centrality_directed(G, method="degree", k_approx=None):
    """
    Computes centrality for directed graph.

    Args:
        G: NetworkX DiGraph
        method: 'degree', 'in_degree', 'out_degree', 'total_degree',
                'pagerank', or 'betweenness'
        k_approx: int (optional), number of sample nodes for approx betweenness

    Returns:
        Dictionary {node: score}
    """
    if not isinstance(G, nx.DiGraph):
        raise TypeError("compute_centrality_directed() chỉ dùng cho DiGraph")

    if method == "degree" or method == "total_degree":
        # Tổng in-degree + out-degree (total degree)
        return dict(G.degree())

    elif method == "in_degree":
        # Chỉ in-degree (số cạnh vào)
        return dict(G.in_degree())

    elif method == "out_degree":
        # Chỉ out-degree (số cạnh ra)
        return dict(G.out_degree())

    elif method == "pagerank":
        # PageRank có tính đến hướng (follow outgoing edges)
        try:
            return nx.pagerank(G, alpha=0.85)
        except nx.PowerIterationFailedConvergence:
            # Fallback về degree nếu không hội tụ
            return dict(G.degree())

    elif method == "betweenness":
        # Betweenness centrality có tính đến hướng
        if k_approx and k_approx < len(G):
            return nx.betweenness_centrality(G, k=k_approx, normalized=True)
        else:
            return nx.betweenness_centrality(G, normalized=True)

    else:
        raise ValueError(f"Unknown centrality method: {method}")

def random_removal_curves_directed(G, fracs, trials=10, seed=123):
    """
    Thực hiện random removal attack trên directed graph và track SCC metrics.

    Args:
        G: NetworkX DiGraph
        fracs: Array of removal fractions (0.0 to 1.0)
        trials: Number of Monte Carlo trials for each fraction
        seed: Random seed for reproducibility

    Returns:
        Tuple of (scc_fractions, diameters, avg_path_lengths)
    """
    if not isinstance(G, nx.DiGraph):
        raise TypeError("random_removal_curves_directed_scc() chỉ dùng cho DiGraph")

    rng = random.Random(seed)
    N0 = G.number_of_nodes()
    nodes_all = list(G.nodes())

    scc_vals, dia_vals, apl_vals = [], [], []

    for f in fracs:
        k = int(round(f * N0))
        scc_trial, dia_trial, apl_trial = [], [], []

        for _ in range(trials):
            nodes = nodes_all[:]
            rng.shuffle(nodes)
            H = G.copy()
            H.remove_nodes_from(nodes[:k])

            scc_trial.append(scc_fraction(H, N0))
            dia, apl = compute_metrics_fastest(H)
            dia_trial.append(dia)
            apl_trial.append(apl)

        scc_vals.append(float(np.mean(scc_trial)))
        dia_vals.append(float(np.nanmean(dia_trial)))
        apl_vals.append(float(np.nanmean(apl_trial)))

    return np.array(scc_vals), np.array(dia_vals), np.array(apl_vals)


def targeted_degree_curves_directed(G, fracs, method="degree", mode="static", k_approx=None):
    """
    Thực hiện targeted removal attack trên directed graph và track SCC metrics.

    Args:
        G: NetworkX DiGraph
        fracs: Array of removal fractions (0.0 to 1.0)
        method: Centrality method ('degree', 'betweenness', 'pagerank', etc.)
        mode: 'static' (compute centrality once) or 'adaptive' (recompute after each removal)
        k_approx: Optional parameter for approximate betweenness

    Returns:
        Tuple of (scc_fractions, diameters, avg_path_lengths)
    """
    if not isinstance(G, nx.DiGraph):
        raise TypeError("targeted_degree_curves_directed_scc() chỉ dùng cho DiGraph")

    N0 = G.number_of_nodes()
    scc_vals, dia_vals, apl_vals = [], [], []

    if mode == "static":
        # Tính centrality một lần dựa trên graph gốc
        cent = compute_centrality_directed(G, method=method, k_approx=k_approx)
        order = [n for n, _ in sorted(cent.items(), key=lambda x: (-x[1], str(x[0])))]

        for f in fracs:
            k = int(round(f * N0))
            H = G.copy()
            H.remove_nodes_from(order[:k])

            scc_vals.append(scc_fraction(H, N0))
            dia, apl = compute_metrics_fastest(H)
            dia_vals.append(dia)
            apl_vals.append(apl)

    else:  # adaptive
        print(f"--- Running ADAPTIVE {method} attack on DIRECTED graph (SCC-Exact) ---")
        H = G.copy()

        # Chuyển fracs thành số lượng node cần xóa
        targets = [int(round(f * N0)) for f in fracs]

        removed_count = 0
        current_target_idx = 0

        # Lưu kết quả cho f=0 (nếu có trong fracs)
        if targets and targets[0] == 0:
            scc_vals.append(scc_fraction(H, N0))
            dia, apl = compute_metrics_fastest(H)
            dia_vals.append(dia)
            apl_vals.append(apl)
            current_target_idx += 1

        while current_target_idx < len(targets) and H.number_of_nodes() > 0:
            target_k = targets[current_target_idx]

            while removed_count < target_k and H.number_of_nodes() > 0:
                # Tính lại centrality trên đồ thị hiện tại H
                cent = compute_centrality_directed(H, method=method, k_approx=k_approx)

                if not cent:
                    break

                # Tìm node max score
                best_node = max(cent.items(), key=lambda x: (x[1], str(x[0])))[0]

                H.remove_node(best_node)
                removed_count += 1

            # Đã đạt mốc f, ghi lại kết quả
            scc_vals.append(scc_fraction(H, N0))
            dia, apl = compute_metrics_fastest(H)
            dia_vals.append(dia)
            apl_vals.append(apl)

            current_target_idx += 1

    return np.array(scc_vals), np.array(dia_vals), np.array(apl_vals)

"""## Attack on Origin Directed Graph

"""

# Random failures (Monte Carlo simulation)
rand_LCC, rand_DIA, rand_APL = random_removal_curves_directed(
    G_di,
    FRACS,
    trials=TRIALS,
    seed=123
)

# Approximate betweenness cho tốc độ
k_approx_value = min(200, G_di.number_of_nodes() // 2)

# Targeted attacks by Degree
targ_LCC_degree, targ_DIA_degree, targ_APL_degree = targeted_degree_curves_directed(
    G_di,
    FRACS,
    method="degree",
    mode=ATTACK_MODE
)

# Targeted attacks by PageRank
targ_LCC_pagerank, targ_DIA_pagerank, targ_APL_pagerank = targeted_degree_curves_directed(
    G_di,
    FRACS,
    method="pagerank",
    mode=ATTACK_MODE
)

# Targeted attacks by Betweenness
targ_LCC_betweenness, targ_DIA_betweenness, targ_APL_betweenness = targeted_degree_curves_directed(
    G_di,
    FRACS,
    method="betweenness",
    mode=ATTACK_MODE,
    k_approx=k_approx_value
)

# ========== COMPUTE R-INDEX (Area Under Curve) ==========

R_rand_di = R_index(FRACS, rand_LCC)
R_targ_degree_di = R_index(FRACS, targ_LCC_degree)
R_targ_pagerank_di = R_index(FRACS, targ_LCC_pagerank)
R_targ_betweenness_di = R_index(FRACS, targ_LCC_betweenness)

results = {
    "Attack Type": [
        "Random Failures",
        "Targeted (Degree)",
        "Targeted (PageRank)",
        "Targeted (Betweenness)"
    ],
    "R-index (SCC)": [
        R_rand_di,
        R_targ_degree_di,
        R_targ_pagerank_di,
        R_targ_betweenness_di
    ]
}

df_results = pd.DataFrame(results)
print("### R-index Results for Original Directed Graph\n")
display(df_results.style.format(precision=4))

# Plot LCC
plot_robustness_curves(
    "OpenFlights Robustness — LCC",
    "LCC size / N0",
    rand_LCC, targ_LCC_degree, targ_LCC_pagerank, targ_LCC_betweenness,
    "robustness_lcc.png"
)

# Plot Diameter
plot_robustness_curves(
    "OpenFlights Robustness — Diameter",
    "Approx. Diameter of LCC",
    rand_DIA, targ_DIA_degree, targ_DIA_pagerank, targ_DIA_betweenness,
    "robustness_diameter.png"
)

# Plot Average Path Length
plot_robustness_curves(
    "OpenFlights Robustness — Average Path Length",
    "Approx. Average Path Length",
    rand_APL, targ_APL_degree, targ_APL_pagerank, targ_APL_betweenness,
    "robustness_Average_Path_Length.png"
)

"""## Các phương pháp phòng thủ trên mạng lưới

### Phương pháp: Add edges
"""

import random

def defense_strategy_inter_community_bridge(G, k_edges_to_add=500):
    """
    Chiến lược Cầu nối Liên Cụm (Inter-Community Bridge).
    Mục đích: Nối các cộng đồng (quốc gia/khu vực) lại với nhau bằng đường bay thẳng,
    bỏ qua các Hub trung chuyển quốc tế (vốn sẽ bị xóa).
    """
    G_def = G.copy()
    added_edges = []

    # 1. Phát hiện cộng đồng (Community Detection)
    # Dùng là Label Propagation
    G_undir = G_def.to_undirected()
    communities = list(nx.community.label_propagation_communities(G_undir))

    # Lọc bỏ các cộng đồng quá bé (< 5 nút)
    valid_communities = [list(c) for c in communities if len(c) > 5]

    print(f"Phát hiện {len(valid_communities)} cộng đồng lớn.")

    # 2. Tạo cầu nối giữa các cộng đồng
    count = 0
    while count < k_edges_to_add:
        # Chọn ngẫu nhiên 2 cộng đồng khác nhau
        if len(valid_communities) < 2: break
        c1, c2 = random.sample(valid_communities, 2)

        # Chọn ngẫu nhiên 1 nút từ mỗi cộng đồng
        u = random.choice(c1)
        v = random.choice(c2)

        if not G_def.has_edge(u, v) and G_def.degree(u) < 200 and G_def.degree(v) < 200:
            # Thêm cạnh 2 chiều (Cầu nối song phương)
            G_def.add_edge(u, v)
            G_def.add_edge(v, u)
            added_edges.append((u, v))
            count += 1

    print(f"--- Đã thêm {len(added_edges)} cầu nối liên vùng (Inter-Community Bridges) ---")
    return G_def, added_edges

"""### Phương pháp: đảo cạnh (Schneider rewiring edge)
đây chỉ là phương pháp thử nghiệm, dựa trên bài báo của schneider et al.
"""

import networkx as nx
import numpy as np
import random
from typing import Any, Dict, Tuple, List, Optional

class DSU:
    __slots__ = ("p", "sz")
    def __init__(self, n: int):
        self.p = list(range(n))
        self.sz = [1] * n

    def find(self, a: int) -> int:
        path = []
        while self.p[a] != a:
            path.append(a)
            a = self.p[a]
        for node in path:
            self.p[node] = a
        return a

    def union(self, a: int, b: int) -> int:
        pa, pb = self.find(a), self.find(b)
        if pa == pb:
            return self.sz[pa]
        if self.sz[pa] < self.sz[pb]:
            pa, pb = pb, pa
        self.p[pb] = pa
        self.sz[pa] += self.sz[pb]
        return self.sz[pa]

def R_index(fracs: np.ndarray, curve: np.ndarray) -> float:
    return float(np.trapz(curve, fracs))

def _static_order_by_degree(G: nx.DiGraph) -> List[Any]:

    deg = dict(G.degree())
    return [n for n, _ in sorted(deg.items(), key=lambda x: (-x[1], str(x[0])))]

def lcc_curve_static_dsu_directed(G: nx.DiGraph, fracs: np.ndarray, order: List[Any]) -> np.ndarray:

    G_undir = G.to_undirected()

    node_list = list(G.nodes())
    idx = {u: i for i, u in enumerate(node_list)}
    n = len(node_list)
    if n == 0:
        return np.zeros_like(fracs, dtype=float)

    active = [False] * n
    dsu = DSU(n)
    max_cc = 0
    lcc_after_k = np.zeros(n + 1, dtype=int)
    lcc_after_k[n] = 0

    rev = list(reversed(order))
    for t, u in enumerate(rev, start=1):
        iu = idx[u]
        active[iu] = True
        for v in G_undir.adj[u]:
            iv = idx[v]
            if active[iv]:
                max_cc = max(max_cc, dsu.union(iu, iv))
        max_cc = max(max_cc, 1)
        lcc_after_k[n - t] = max_cc

    ks = np.clip(np.rint(fracs * n).astype(int), 0, n)
    return lcc_after_k[ks].astype(float) / float(n)

def robustness_R_static_fast(G: nx.DiGraph, fracs: np.ndarray, order: List[Any]) -> float:
    curve = lcc_curve_static_dsu_directed(G, fracs, order)
    return R_index(fracs, curve)


def optimize_schneider_directed(
    G: nx.DiGraph,
    fracs: Optional[np.ndarray] = None,
    max_trials: int = 5000,
    patience: int = 1000,
    min_delta_R: float = 1e-6,
    seed: int = 42,
    prefilter: bool = True
) -> Tuple[nx.DiGraph, Dict[str, Any]]:

    if fracs is None:
        fracs = np.linspace(0, 0.3, 21)

    rng = random.Random(seed)
    Gr = G.copy()

    order = _static_order_by_degree(Gr)
    deg = dict(Gr.degree()) # Total degree

    # Tính R ban đầu
    R_best = robustness_R_static_fast(Gr, fracs, order)
    print(f"R-index ban đầu: {R_best:.5f}")

    edges = list(Gr.edges())
    accepted = 0
    no_improve = 0
    r_evals = 1

    def score_degree_mixing(u, v, x, y, u_new, v_new, x_new, y_new) -> int:
        old_diff = abs(deg[u]-deg[v]) + abs(deg[x]-deg[y])
        new_diff = abs(deg[u_new]-deg[v_new]) + abs(deg[x_new]-deg[y_new])
        return new_diff - old_diff

    for t in range(1, max_trials + 1):
        if no_improve >= patience:
            print(f"Dừng sớm tại vòng {t} do không cải thiện.")
            break

        # 1. Chọn ngẫu nhiên 2 cạnh: u->v và x->y

        if len(edges) < 2: break

        idx1, idx2 = rng.sample(range(len(edges)), 2)
        u, v = edges[idx1]
        x, y = edges[idx2]

        # 2. Logic Swap cho Directed:
        # Swap: u->v, x->y  THÀNH  u->y, x->v
        # Để bảo toàn In/Out degree của tất cả các nút.

        # Kiểm tra điều kiện hợp lệ
        # - Không tạo self-loop
        if u == y or x == v:
            continue
        if Gr.has_edge(u, y) or Gr.has_edge(x, v):
            continue
        if u == x and v == y:
            continue

        if prefilter:
            if score_degree_mixing(u, v, x, y, u, y, x, v) > 0:
                continue

        #  Thực hiện Swap thử
        Gr.remove_edge(u, v)
        Gr.remove_edge(x, y)
        Gr.add_edge(u, y)
        Gr.add_edge(x, v)

        #  Tính lại R
        R_new = robustness_R_static_fast(Gr, fracs, order)
        r_evals += 1

        # 6. Quyết định
        if R_new > R_best + min_delta_R:
            # Chấp nhận cải thiện
            R_best = R_new
            edges[idx1] = (u, y)
            edges[idx2] = (x, v)
            accepted += 1
            no_improve = 0
            # print(f"  Iter {t}: Tăng R -> {R_best:.5f}")
        else:
            # Hoàn tác (Revert)
            Gr.remove_edge(u, y)
            Gr.remove_edge(x, v)
            Gr.add_edge(u, v)
            Gr.add_edge(x, y)
            no_improve += 1

    info = {
        "R_best_final": float(R_best),
        "accepted_swaps": accepted,
        "trials_done": t,
        "R_evaluations": r_evals
    }
    return Gr, info

"""## Kịch bản phòng thủ ->  tấn công
phòng thủ mạng sử dụng 2 phương pháp, so sánh với mạng gốc

### Phòng thủ sử dụng phương pháp add edges
"""

budget_k = 2000
G_alg, edges_alg = defense_strategy_inter_community_bridge(G_di, k_edges_to_add=budget_k)

rand_LCC_def_add, rand_DIA_def_add, rand_APL_def_add = random_removal_curves_directed(
    G_alg,
    FRACS,
    trials=TRIALS,
    seed=123
)

# Approximate betweenness cho tốc độ
k_approx_value = min(200, G_alg.number_of_nodes() // 2)

# Targeted attacks by Degree
targ_LCC_degree_def_add, targ_DIA_degree_def_add, targ_APL_degree_def_add = targeted_degree_curves_directed(
    G_alg,
    FRACS,
    method="degree",
    mode=ATTACK_MODE
)

# Targeted attacks by PageRank
targ_LCC_pagerank_def_add, targ_DIA_pagerank_def_add, targ_APL_pagerank_def_add = targeted_degree_curves_directed(
    G_alg,
    FRACS,
    method="pagerank",
    mode=ATTACK_MODE
)

# Targeted attacks by Betweenness
targ_LCC_betweenness_def_add, targ_DIA_betweenness_def_add, targ_APL_betweenness_def_add = targeted_degree_curves_directed(
    G_alg,
    FRACS,
    method="betweenness",
    mode=ATTACK_MODE,
    k_approx=k_approx_value
)

# ========== COMPUTE R-INDEX (Area Under Curve) ==========

R_rand_def_add = R_index(FRACS, rand_LCC_def_add)
R_targ_degree_def_add = R_index(FRACS, targ_LCC_degree_def_add)
R_targ_pagerank_def_add = R_index(FRACS, targ_LCC_pagerank_def_add)
R_targ_betweenness_def_add = R_index(FRACS, targ_LCC_betweenness_def_add)

results = {
    "Attack Type": [
        "Random Failures",
        "Targeted (Degree)",
        "Targeted (PageRank)",
        "Targeted (Betweenness)"
    ],
    "R-index (LCC) using def add": [
        R_rand_def_add,
        R_targ_degree_def_add,
        R_targ_pagerank_def_add,
        R_targ_betweenness_def_add
    ]
}

df_results = pd.DataFrame(results)
print("### R-index Results for Defense Directed Graph\n")
display(df_results.style.format(precision=4))

# Plot LCC
plot_robustness_curves(
    "OpenFlights Robustness — LCC",
    "LCC size / N0",
    rand_LCC_def_add, targ_LCC_degree_def_add, targ_LCC_pagerank_def_add, targ_LCC_betweenness_def_add,
    "robustness_lcc_def_add.png"
)

# Plot Diameter
plot_robustness_curves(
    "OpenFlights Robustness — Diameter",
    "Approx. Diameter of LCC",
    rand_DIA_def_add, targ_DIA_degree_def_add, targ_DIA_pagerank_def_add, targ_DIA_betweenness_def_add,
    "robustness_diameter_def_add.png"
)

# Plot Average Path Length
plot_robustness_curves(
    "OpenFlights Robustness — Average Path Length",
    "Approx. Average Path Length",
    rand_APL_def_add, targ_APL_degree_def_add, targ_APL_pagerank_def_add, targ_APL_betweenness_def_add,
    "robustness_Average_Path_Length_def_add.png"
)

"""#### So sánh R index mạng gốc và mạng đã được phòng thủ với add edge"""

import matplotlib.pyplot as plt
import seaborn as sns

# Prepare data for comparison
comparison_data = {
    'Attack Type': ['Random', 'Targeted Degree', 'Targeted PageRank', 'Targeted Betweenness'],
    'Original': [R_rand_di, R_targ_degree_di, R_targ_pagerank_di, R_targ_betweenness_di],
    'Add edge Defense': [R_rand_def_add, R_targ_degree_def_add, R_targ_pagerank_def_add, R_targ_betweenness_def_add]
}
df_comparison = pd.DataFrame(comparison_data)

# Melt the DataFrame for seaborn's grouped bar plot
df_melted = df_comparison.melt(id_vars='Attack Type', var_name='Network Type', value_name='R-index (LCC)')

plt.figure(figsize=(10, 6))
sns.barplot(x='Attack Type', y='R-index (LCC)', hue='Network Type', data=df_melted, palette='coolwarm')
plt.title('Comparison of R-index (LCC): Original vs Add Edge Defense')
plt.xlabel('Attack Type')
plt.ylabel('R-index (LCC)')
plt.ylim(0, df_melted['R-index (LCC)'].max() * 1.1) # Set y-limit to slightly above max R-index
plt.tight_layout()
plt.savefig(OUT_DIR/"r_index_comparison_original_vs_def_add.png")
plt.show()
print(OUT_DIR/"r_index_comparison_original_vs_def_add.png")

"""### Phòng thử sử dụng edge rewiring (schneider)"""

G_sch, stats = optimize_schneider_directed(
    G_di,
    max_trials=5000,
    patience=2000,     # Dừng nếu 2000 lần liên tiếp không cải thiện
    seed=42
)

rand_LCC_def_sch, rand_DIA_def_sch, rand_APL_def_sch = random_removal_curves_directed(
    G_sch,
    FRACS,
    trials=TRIALS,
    seed=123
)

k_approx_value = min(200, G_sch.number_of_nodes() // 2)

# Targeted attacks by Degree
targ_LCC_degree_def_sch, targ_DIA_degree_def_sch, targ_APL_degree_def_sch = targeted_degree_curves_directed(
    G_sch,
    FRACS,
    method="degree",
    mode=ATTACK_MODE
)

# Targeted attacks by PageRank
targ_LCC_pagerank_def_sch, targ_DIA_pagerank_def_sch, targ_APL_pagerank_def_sch = targeted_degree_curves_directed(
    G_sch,
    FRACS,
    method="pagerank",
    mode=ATTACK_MODE
)

# Targeted attacks by Betweenness
targ_LCC_betweenness_def_sch, targ_DIA_betweenness_def_sch, targ_APL_betweenness_def_sch = targeted_degree_curves_directed(
    G_sch,
    FRACS,
    method="betweenness",
    mode=ATTACK_MODE,
    k_approx=k_approx_value
)

# ========== COMPUTE R-INDEX (Area Under Curve) ==========

R_rand_def_sch = R_index(FRACS, rand_LCC_def_sch)
R_targ_degree_def_sch = R_index(FRACS, targ_LCC_degree_def_sch)
R_targ_pagerank_def_sch = R_index(FRACS, targ_LCC_pagerank_def_sch)
R_targ_betweenness_def_sch = R_index(FRACS, targ_LCC_betweenness_def_sch)

# ========== RESULTS SUMMARY ==========

print(f"R-index(SCC) — Random Failures:         {R_rand_def_sch:.4f}")
print(f"R-index(SCC) — Targeted (Degree):       {R_targ_degree_def_sch:.4f}")
print(f"R-index(SCC) — Targeted (PageRank):     {R_targ_pagerank_def_sch:.4f}")
print(f"R-index(SCC) — Targeted (Betweenness):  {R_targ_betweenness_def_sch:.4f}")

results = {
    "Attack Type": [
        "Random Failures",
        "Targeted (Degree)",
        "Targeted (PageRank)",
        "Targeted (Betweenness)"
    ],
    "R-index (LCC) using def sch": [
        R_rand_def_sch,
        R_targ_degree_def_sch,
        R_targ_pagerank_def_sch,
        R_targ_betweenness_def_sch
    ]
}

df_results = pd.DataFrame(results)
print("### R-index Results for Defense Directed Graph\n")
display(df_results.style.format(precision=4))

# Plot LCC
plot_robustness_curves(
    "OpenFlights Robustness — LCC",
    "LCC size / N0",
    rand_LCC_def_sch, targ_LCC_degree_def_sch, targ_LCC_pagerank_def_sch, targ_LCC_betweenness_def_sch,
    "robustness_lcc_def_sch.png"
)

# Plot Diameter
plot_robustness_curves(
    "OpenFlights Robustness — Diameter",
    "Approx. Diameter of LCC",
    rand_DIA_def_sch, targ_DIA_degree_def_sch, targ_DIA_pagerank_def_sch, targ_DIA_betweenness_def_sch,
    "robustness_diameter_def_sch.png"
)

# Plot Average Path Length
plot_robustness_curves(
    "OpenFlights Robustness — Average Path Length",
    "Approx. Average Path Length",
    rand_APL_def_sch, targ_APL_degree_def_sch, targ_APL_pagerank_def_sch, targ_APL_betweenness_def_sch,
    "robustness_Average_Path_Length_def_sch.png"
)

"""#### So sánh R index mạng gốc và mạng đã được phòng thủ với rewiring schneider"""

import matplotlib.pyplot as plt
import seaborn as sns

# Prepare data for comparison
comparison_data = {
    'Attack Type': ['Random', 'Targeted Degree', 'Targeted PageRank', 'Targeted Betweenness'],
    'Original': [R_rand_di, R_targ_degree_di, R_targ_pagerank_di, R_targ_betweenness_di],
    'edge rewiring Defense': [R_rand_def_sch,
        R_targ_degree_def_sch,
        R_targ_pagerank_def_sch,
        R_targ_betweenness_def_sch]
}
df_comparison = pd.DataFrame(comparison_data)

# Melt the DataFrame for seaborn's grouped bar plot
df_melted = df_comparison.melt(id_vars='Attack Type', var_name='Network Type', value_name='R-index (LCC)')

plt.figure(figsize=(10, 6))
sns.barplot(x='Attack Type', y='R-index (LCC)', hue='Network Type', data=df_melted, palette='coolwarm')
plt.title('Comparison of R-index (LCC): Original vs edge rewiring Defense')
plt.xlabel('Attack Type')
plt.ylabel('R-index (LCC)')
plt.ylim(0, df_melted['R-index (LCC)'].max() * 1.1) # Set y-limit to slightly above max R-index
plt.tight_layout()
plt.savefig(OUT_DIR/"r_index_comparison_original_vs_def_sch.png")
plt.show()
print(OUT_DIR/"r_index_comparison_original_vs_def_sch.png")

"""## Kịch bản Tấn công -> Phòng thủ
Thực hiện xóa các node top-hub dựa trên degree, sau đó phòng thủ với phương pháp Thêm cạnh (Add Edges) và so sánh R index trên các trạng thái của đồ thị.
"""

import numpy as np
import matplotlib.pyplot as plt
plt.style.use("seaborn-v0_8")

N0 = G_di.number_of_nodes()
f_attack = 0.10
k_remove = int(round(f_attack * N0))

# Sắp thứ tự node theo degree giảm dần
cent_deg = compute_centrality_directed(G_di, method="degree")
order_deg = [n for n,_ in sorted(cent_deg.items(),
                                 key=lambda x: (-x[1], str(x[0])))]

# Tạo G_damaged
G_damaged = G_di.copy()
G_damaged.remove_nodes_from(order_deg[:k_remove])

print(f"\n--- After attack (remove {f_attack*100:.1f}% top-degree nodes) ---")
print(f"Số node: {G_damaged.number_of_nodes()}, số cạnh: {G_damaged.number_of_edges()}")

budget_k = 2000
G_repaired, edges_repaired = defense_strategy_inter_community_bridge(G_damaged, k_edges_to_add=budget_k)

rand_LCC_orig, _, _ = random_removal_curves_directed(G_di,          FRACS, trials=TRIALS, seed=123)
rand_LCC_dam,  _, _ = random_removal_curves_directed(G_damaged,  FRACS, trials=TRIALS, seed=123)
rand_LCC_rep,  _, _ = random_removal_curves_directed(G_repaired, FRACS, trials=TRIALS, seed=123)

R_rand_orig = R_index(FRACS, rand_LCC_orig)
R_rand_dam  = R_index(FRACS, rand_LCC_dam)
R_rand_rep  = R_index(FRACS, rand_LCC_rep)

print("\n--- R-index under RANDOM attack ---")
print(f"Original : {R_rand_orig:.3f}")
print(f"Damaged  : {R_rand_dam:.3f}")
print(f"Repaired : {R_rand_rep:.3f}")

plt.figure(figsize=(7,5))
plt.plot(FRACS, rand_LCC_orig, label=f"Original (R={R_rand_orig:.3f})", marker="o")
plt.plot(FRACS, rand_LCC_dam,  label=f"Damaged (R={R_rand_dam:.3f})",  marker="s")
plt.plot(FRACS, rand_LCC_rep,  label=f"Repaired (R={R_rand_rep:.3f})", marker="^")

plt.xlabel("fraction of removed nodes (f)")
plt.ylabel("LCC fraction S(f)")
plt.title("LCC(f) random attack\nOriginal vs Damaged vs Repaired")
plt.ylim(-0.05, 1.05)
plt.grid(True, alpha=0.3)
plt.legend()
plt.tight_layout()
plt.show()

labels = ["Original", "Damaged", "Repaired"]
R_vals = [R_rand_orig, R_rand_dam, R_rand_rep]

plt.figure(figsize=(6,4))
bars = plt.bar(labels, R_vals, color=["tab:green", "tab:red", "tab:blue"], alpha=0.8)
plt.ylabel("R-index (LCC, random attack)")
plt.title("Compare Robustness: before attack, after attack, after defense")

for b, r in zip(bars, R_vals):
    plt.text(b.get_x() + b.get_width()/2, b.get_height() + 0.01,
             f"{r:.3f}", ha="center", va="bottom", fontsize=9)

plt.ylim(0, max(R_vals)*1.15)
plt.tight_layout()
plt.show()

"""## Other"""

# Lấy 15 cạnh đầu tiên
top_15_edges = edges_alg[:15]

table_data = []

for idx, (u, v) in enumerate(top_15_edges, 1):
    # Lấy thông tin từ node attributes
    u_info = G_alg.nodes[u]
    v_info = G_alg.nodes[v]

    # Lấy distance từ edge attributes
    edge_data = G_alg[u][v]
    distance = edge_data.get('weight', 0)  # 'weight' là tên thuộc tính chứa khoảng cách

    row = {
        "Rank": idx,
        "City A": u_info.get('city', 'Unknown'),
        "IATA A": u_info.get('iata', str(u)),
        "City B": v_info.get('city', 'Unknown'),
        "IATA B": v_info.get('iata', str(v)),
        "Distance (km)": distance
    }
    table_data.append(row)

df_added = pd.DataFrame(table_data)
print("\n=== TOP 15 CẠNH ĐÃ THÊM VÀO ===")
print(df_added.to_markdown(index=False, floatfmt=".2f"))

"""## Case study

### Phân tích tuyến bay RNB -> KVL
"""

import networkx as nx
import pandas as pd
import matplotlib.pyplot as plt
from geopy.distance import great_circle

def add_distance_weights(graph, airports_df, force_recalculate=False):
    """
    Tính và thêm trọng số 'weight' (khoảng cách km) cho tất cả các cạnh trong đồ thị.

    Parameters:
    -----------
    graph : nx.Graph hoặc nx.DiGraph
        Đồ thị cần thêm trọng số
    airports_df : pd.DataFrame
        DataFrame chứa thông tin sân bay (airport_id, lat, lon)
    force_recalculate : bool, default=False
        Nếu True, tính lại trọng số cho tất cả các cạnh (kể cả đã có weight)
    """
    print(f"Calculating edge distances for graph with {graph.number_of_edges()} edges...")

    coords = airports_df.set_index("airport_id")[["lat", "lon"]].to_dict("index")

    count = 0
    for u, v, data in graph.edges(data=True):
        # Bỏ qua nếu đã có weight VÀ không yêu cầu tính lại
        if "weight" in data and not force_recalculate:
            continue

        if u in coords and v in coords:
            pos_u = (coords[u]["lat"], coords[u]["lon"])
            pos_v = (coords[v]["lat"], coords[v]["lon"])
            try:
                dist_km = great_circle(pos_u, pos_v).kilometers
                data["weight"] = dist_km
                count += 1
            except ValueError:
                data["weight"] = 99999.0
                count += 1
        else:
            data["weight"] = 99999.0
            count += 1

    print(f"-> Added/Updated weights for {count} edges.")
    return graph

def analyze_flight_route(G, src_iata, dst_iata, attack_nodes_iata=None):
    # Tìm Airport ID
    try:
        src_row = ap[ap["iata"] == src_iata]
        dst_row = ap[ap["iata"] == dst_iata]
        if src_row.empty or dst_row.empty:
            print(f"Error: Invalid IATA code {src_iata} or {dst_iata}")
            return

        src_id = src_row.iloc[0]["airport_id"]
        dst_id = dst_row.iloc[0]["airport_id"]
        src_name = src_row.iloc[0]["name"]
        dst_name = dst_row.iloc[0]["name"]
    except Exception as e:
        print(f"Error looking up airports: {e}")
        return

    print(f"\n{'='*60}")
    print(f"CASE STUDY: {src_iata} ({src_name}) -> {dst_iata} ({dst_name})")
    print(f"{'='*60}")

    try:
        path = nx.shortest_path(G, source=src_id, target=dst_id, weight="weight")
        dist = nx.shortest_path_length(G, source=src_id, target=dst_id, weight="weight")

        print(f"\n[1] ORIGINAL ROUTE (Total: {dist:.2f} km)")
        route_str = [G.nodes[n].get("iata", str(n)) for n in path]
        print(f"   Route: {' -> '.join(route_str)}")
        print(f"   Hops: {len(path)-1}")

    except nx.NetworkXNoPath:
        print(f"No path found between {src_iata} and {dst_iata}")
        return

    target_ids = []
    if attack_nodes_iata:
        for code in attack_nodes_iata:
            row = ap[ap["iata"] == code]
            if not row.empty:
                target_ids.append(row.iloc[0]["airport_id"])

    if not target_ids:
        print("\n   (!) No attack targets specified.")
        return

    print(f"\n[2] ATTACK SIMULATION")
    print(f"   Removing nodes: {attack_nodes_iata}")

    G_attack = G.copy()
    G_attack.remove_nodes_from(target_ids)

    try:
        new_path = nx.shortest_path(G_attack, source=src_id, target=dst_id, weight="weight")
        new_dist = nx.shortest_path_length(G_attack, source=src_id, target=dst_id, weight="weight")

        print(f"\n[3] REROUTED PATH (Total: {new_dist:.2f} km)")
        new_route_str = [G.nodes[n].get("iata", str(n)) for n in new_path]
        print(f"   New Route: {' -> '.join(new_route_str)}")
        print(f"   Impact: +{new_dist - dist:.2f} km")

    except nx.NetworkXNoPath:
        print(f"\n[3] SYSTEM FAILURE: Network disconnected!")

def adaptive_route_attack_simulation(G, G_def, src_iata, dst_iata):
    try:
        src_id = ap[ap["iata"] == src_iata].iloc[0]["airport_id"]
        dst_id = ap[ap["iata"] == dst_iata].iloc[0]["airport_id"]
    except:
        print("Error: Mã sân bay không hợp lệ.")
        return

    print(f"\n{'='*70}")
    print(f"ADAPTIVE ATTACK SIMULATION: {src_iata} -> {dst_iata}")
    print(f"{'='*70}")

    try:
        path = nx.shortest_path(G, source=src_id, target=dst_id, weight="weight")
        transit_ids = path[1:-1]
        transit_codes = [ap[ap['airport_id']==nid].iloc[0]['iata'] for nid in transit_ids]

        print(f"Current Optimal Route: {' -> '.join([ap[ap['airport_id']==n].iloc[0]['iata'] for n in path])}")
        print(f"Critical Transit Nodes: {transit_codes}")

        if not transit_codes:
            print("(!) Đường bay thẳng. Không có transit để tấn công.")
            return
    except nx.NetworkXNoPath:
        print("Không có đường bay ban đầu.")
        return

    results_orig = []
    results_def = []
    labels = []

    # Kịch bản 0: Baseline (Không tấn công)
    d_base_orig = nx.shortest_path_length(G, src_id, dst_id, weight="weight")
    try:
        d_base_def = nx.shortest_path_length(G_def, src_id, dst_id, weight="weight")
    except: d_base_def = float('inf')

    results_orig.append(d_base_orig)
    results_def.append(d_base_def)
    labels.append("None")

    print("\n--- ATTACK RESULTS ---")
    print(f"{'Target':<10} | {'Original (km)':<15} | {'Defended (km)':<15} | {'Delta'}")
    print("-" * 60)

    for target_code, target_id in zip(transit_codes, transit_ids):
        # Tấn công G
        G_temp = G.copy()
        G_temp.remove_node(target_id)
        try: d_orig = nx.shortest_path_length(G_temp, src_id, dst_id, weight="weight")
        except: d_orig = float('inf')

        # Tấn công G_def
        G_def_temp = G_def.copy()
        G_def_temp.remove_node(target_id)
        try: d_def = nx.shortest_path_length(G_def_temp, src_id, dst_id, weight="weight")
        except: d_def = float('inf')

        results_orig.append(d_orig)
        results_def.append(d_def)
        labels.append(f"-{target_code}")

        # In kết quả
        s_orig = f"{d_orig:.1f}" if d_orig != float('inf') else "DEAD"
        s_def = f"{d_def:.1f}" if d_def != float('inf') else "DEAD"
        delta = f"{d_def - d_orig:.1f}" if (d_orig!=float('inf') and d_def!=float('inf')) else '---'
        print(f"{target_code:<10} | {s_orig:<15} | {s_def:<15} | {delta}")

    # Kịch bản Combo: Tấn công 2 transit nodes quan trọng nhất
    # Chọn tự động dựa trên transit_codes thay vì hard-code

    if len(transit_codes) >= 2:
        # Chọn 2 node đầu tiên (gần nguồn nhất) hoặc 2 node cuối (gần đích nhất)
        # Hoặc chọn 2 node ở giữa (quan trọng nhất)
        # Ở đây tôi chọn 2 node đầu tiên để test
        combo_targets = transit_codes[:2]  # Lấy 2 cái đầu

        # Hoặc nếu muốn chọn node đầu và node cuối:
        # combo_targets = [transit_codes[0], transit_codes[-1]]

    elif len(transit_codes) == 1:
        combo_targets = transit_codes  # Chỉ có 1 node
    else:
        combo_targets = []

    if combo_targets:
        combo_ids = [ap[ap['iata']==c].iloc[0]['airport_id'] for c in combo_targets if len(ap[ap['iata']==c]) > 0]

        if combo_ids:
            # Tấn công G
            G_temp = G.copy()
            G_temp.remove_nodes_from(combo_ids)
            try: d_orig = nx.shortest_path_length(G_temp, src_id, dst_id, weight="weight")
            except: d_orig = float('inf')

            # Tấn công G_def
            G_def_temp = G_def.copy()
            G_def_temp.remove_nodes_from(combo_ids)
            try: d_def = nx.shortest_path_length(G_def_temp, src_id, dst_id, weight="weight")
            except: d_def = float('inf')

            results_orig.append(d_orig)
            results_def.append(d_def)
            combo_label = "+".join(combo_targets)
            labels.append(combo_label)

            s_orig = f"{d_orig:.1f}" if d_orig!=float('inf') else "DEAD"
            s_def = f"{d_def:.1f}" if d_def!=float('inf') else "DEAD"
            print(f"{combo_label:<10} | {s_orig:<15} | {s_def:<15} | ---")

    # Vẽ biểu đồ
    max_val = max([v for v in results_orig + results_def if v != float('inf')] + [10000]) * 1.2
    plot_orig = [v if v != float('inf') else max_val for v in results_orig]
    plot_def = [v if v != float('inf') else max_val for v in results_def]

    x = range(len(labels))
    width = 0.35
    fig, ax = plt.subplots(figsize=(12, 6))  # Tăng width để chứa nhiều label
    ax.bar([i - width/2 for i in x], plot_orig, width, label='Original', color='#ff9999')
    ax.bar([i + width/2 for i in x], plot_def, width, label='Defended', color='#66b3ff')

    for i, v in enumerate(results_orig):
        if v == float('inf'):
            ax.text(i - width/2, max_val*0.95, 'X', ha='center', color='red', fontweight='bold', fontsize=14)
    for i, v in enumerate(results_def):
        if v == float('inf'):
            ax.text(i + width/2, max_val*0.95, 'X', ha='center', color='red', fontweight='bold', fontsize=14)

    ax.set_ylabel('Path Length (km)', fontsize=12)
    ax.set_title(f'Attack Simulation: {src_iata} -> {dst_iata}', fontsize=14, fontweight='bold')
    ax.set_xticks(x)
    ax.set_xticklabels(labels, rotation=45, ha='right')  # Xoay label để dễ đọc
    ax.legend()
    plt.tight_layout()
    plt.show()


add_distance_weights(G_di, ap)
budget_k = 2000
G_alg, edges_alg = defense_strategy_inter_community_bridge(G_di, k_edges_to_add=budget_k)
add_distance_weights(G_alg, ap, force_recalculate=False)

adaptive_route_attack_simulation(G_di, G_alg, "RNB", "KVL")

"""# Experiment: Analysis on Undirected Graph

## Build Undirected Graph
"""

def build_undirected_graph(ap, rt):
    valid = set(ap["airport_id"])
    r = rt[(rt["src_id"].isin(valid)) & (rt["dst_id"].isin(valid))]
    r = r[r["src_id"] != r["dst_id"]].copy()

    G = nx.Graph()
    G.add_nodes_from(ap["airport_id"].tolist())
    G.add_edges_from(zip(r["src_id"], r["dst_id"]))

    attrs = ap.set_index("airport_id")[["name","city","country","iata","icao","lat","lon"]].to_dict("index")
    nx.set_node_attributes(G, attrs)
    return G, r

G, r_clean = build_undirected_graph(ap, rt)
G.number_of_nodes(), G.number_of_edges()
print(f"Số node ban đầu: {G.number_of_nodes()}")
print(f"Số cạnh ban đầu: {G.number_of_edges()}")

largest_cc_nodes = max(nx.connected_components(G), key=len)

G_clean = G.subgraph(largest_cc_nodes).copy()

G = G_clean
N0 = G.number_of_nodes()

print(f"Số node sau khi lọc (LCC): {G.number_of_nodes()}")
print(f"Số cạnh sau khi lọc: {G.number_of_edges()}")

"""## Metrics"""

!pip install networkit

from networkx.algorithms import approximation as apx
import networkit as nk
from math import inf
import random

def lcc_nodes(G):
    return max(nx.connected_components(G), key=len) if G.number_of_nodes() > 0 else set()

def lcc_fraction(G, N0):
    return (len(lcc_nodes(G))/float(N0)) if G.number_of_nodes() > 0 and N0>0 else 0.0

def approx_diameter_of_LCC(G):
    if G.number_of_nodes() == 0:
        return float("nan")
    L = G.subgraph(lcc_nodes(G)).copy()
    if L.number_of_nodes() <= 1:
        return 0.0
    try:
        return float(apx.diameter(L))
    except Exception:

        nodes = list(L.nodes())[:min(100, L.number_of_nodes())]
        lens = []
        for s in nodes:
            lens.extend(nx.single_source_shortest_path_length(L, s).values())
        return float(np.percentile(lens, 90)) if len(lens)>0 else float("nan")

def approx_avg_path_of_LCC(G, max_samples=500):
    if G.number_of_nodes() == 0:
        return float("nan")
    L = G.subgraph(lcc_nodes(G)).copy()
    n = L.number_of_nodes()
    if n <= 1:
        return 0.0
    node_list = list(L.nodes())
    id_map = {node: i for i, node in enumerate(node_list)}
    # Tạo graph NetworKit
    G_nk = nk.graph.Graph(n, weighted=False, directed=False)
    for u, v in L.edges():
        G_nk.addEdge(id_map[u], id_map[v])


    apsp = nk.distance.APSP(G_nk)
    apsp.run()

    # Lấy tất cả khoảng cách hữu hạn và tính trung bình
    dists = []
    for i in range(n):
        for j in range(i+1, n):
            d = apsp.getDistance(i, j)
            if d < inf:
                dists.append(d)

    return float(np.mean(dists)) if dists else float("nan")

def R_index(fracs, curve):
    return float(np.trapezoid(curve, fracs))

"""## Configuration Experiment"""

# Configure experiment
FRACS = np.linspace(0, 1, 51) # 0%..100%
TRIALS = 20
ATTACK_MODE = "static"

"""## Consolidated Plotting"""

def plot_robustness_curves(title, ylabel, rand_curve, targ_degree_curve, targ_pagerank_curve, targ_betweenness_curve, filename):
    plt.figure(figsize=(8,5))
    plt.plot(FRACS*100, rand_curve, label=f"Random (trials={TRIALS})")
    plt.plot(FRACS*100, targ_degree_curve, label=f"Targeted-degree ({ATTACK_MODE})")
    plt.plot(FRACS*100, targ_pagerank_curve, label=f"Targeted-PageRank ({ATTACK_MODE})")
    plt.plot(FRACS*100, targ_betweenness_curve, label=f"Targeted-Betweenness ({ATTACK_MODE})")
    plt.xlabel("Fraction of airports removed (%)")
    plt.ylabel(ylabel)
    plt.title(title)
    plt.legend(); plt.tight_layout()
    plt.savefig(OUT_DIR/filename)
    print(OUT_DIR/filename)

"""## Attack
Tham khảo tấn công
https://github.com/tsantanam/networkx-robustness/blob/main/src/networkx_robustness/networkx_robustness.py

Paper: https://www.nature.com/articles/s41598-024-76264-6
       https://www.m3nets.de/publications/TRMA2015.pdf
"""

def compute_centrality(G, method="degree", k_approx=None):
    if method == "degree":
        return dict(G.degree())

    elif method == "pagerank":
        # PageRank hoạt động tốt trên cả undirected (tương tự eigenvector centrality)
        try:
            return nx.pagerank(G, alpha=0.85)
        except nx.PowerIterationFailedConvergence:
            # Fallback nếu không hội tụ (hiếm gặp với undirected)
            return dict(G.degree())

    elif method == "betweenness":
        # Nếu k_approx được set, dùng xấp xỉ để chạy nhanh hơn
        if k_approx and k_approx < len(G):
            return nx.betweenness_centrality(G, k=k_approx, normalized=True)
        else:
            return nx.betweenness_centrality(G, normalized=True)

    else:
        raise ValueError(f"Unknown centrality method: {method}")

def random_removal_curves(G, fracs, trials=10, seed=123):
    rng = random.Random(seed)
    N0 = G.number_of_nodes()
    nodes_all = list(G.nodes())
    lcc_vals, dia_vals, apl_vals  = [], [], []
    for f in fracs:
        k = int(round(f*N0))
        lcc_trial, dia_trial, apl_trial  = [], [], []
        for _ in range(trials):
            nodes = nodes_all[:]
            rng.shuffle(nodes)
            H = G.copy()
            H.remove_nodes_from(nodes[:k])
            lcc_trial.append(lcc_fraction(H, N0))
            dia_trial.append(approx_diameter_of_LCC(H))
            apl_trial.append(approx_avg_path_of_LCC(H))

        lcc_vals.append(float(np.mean(lcc_trial)))
        dia_vals.append(float(np.nanmean(dia_trial)))
        apl_vals.append(float(np.nanmean(apl_trial)))
    return np.array(lcc_vals), np.array(dia_vals), np.array(apl_vals)

def targeted_degree_curves(G, fracs, method="degree", mode="static", k_approx=None):
    N0 = G.number_of_nodes()
    lcc_vals, dia_vals, apl_vals  = [], [], []
    if mode == "static":
        cent = compute_centrality(G, method=method, k_approx=k_approx)
        order = [n for n,_ in sorted(cent.items(), key=lambda x:(-x[1], x[0]))]
        for f in fracs:
            k = int(round(f*N0))
            H = G.copy()
            H.remove_nodes_from(order[:k])
            lcc_vals.append(lcc_fraction(H, N0))
            dia_vals.append(approx_diameter_of_LCC(H))
            apl_vals.append(approx_avg_path_of_LCC(H))
    else:
        print(f"--- Running ADAPTIVE {method} attack ---")
        H = G.copy()

        # Chuyển fracs thành số lượng node cần xóa tương ứng
        # Ví dụ: fracs=[0.1, 0.2] -> targets=[100, 200]
        targets = [int(round(f * N0)) for f in fracs]


        removed_count = 0
        current_target_idx = 0

        # Lưu kết quả cho f=0 (nếu có trong fracs)
        if 0.0 in fracs:
             lcc_vals.append(lcc_fraction(H, N0))
             dia_vals.append(approx_diameter_of_LCC(H))
             apl_vals.append(approx_avg_path_of_LCC(H))
             current_target_idx += 1

        while current_target_idx < len(targets) and H.number_of_nodes() > 0:
            target_k = targets[current_target_idx]

            # Xóa dần cho đến khi đạt target tiếp theo
            while removed_count < target_k and H.number_of_nodes() > 0:
                # Tính lại centrality trên đồ thị hiện tại H
                cent = compute_centrality(H, method=method, k_approx=k_approx)

                # Tìm node max score
                best_node = max(cent.items(), key=lambda x: x[1])[0]

                H.remove_node(best_node)
                removed_count += 1

            # Đã đạt mốc f, ghi lại kết quả
            lcc_vals.append(lcc_fraction(H, N0))
            dia_vals.append(approx_diameter_of_LCC(H))
            apl_vals.append(approx_avg_path_of_LCC(H))

            current_target_idx += 1

    return np.array(lcc_vals), np.array(dia_vals), np.array(apl_vals)

"""### Attack on origin network"""

# Before attack
N0  = G.number_of_nodes()
E0  = G.number_of_edges()
LCC0 = lcc_fraction(G, N0)
DIA0 = approx_diameter_of_LCC(G)
APL0 = approx_avg_path_of_LCC(G)

print(f"N0 (số sân bay): {N0}")
print(f"E0 (số đường bay): {E0}")
print(f"LCC fraction ban đầu: {LCC0:.3f}")
print(f"Diameter ban đầu: {DIA0:.3f}")
print(f"Average path length ban đầu: {APL0:.3f}")

# Random failures
rand_LCC, rand_DIA, rand_APL = random_removal_curves(G, FRACS, trials=TRIALS, seed=123)

k_approx_value = min(200, G.number_of_nodes() // 2)
# Targeted attacks by degree
targ_LCC_degree, targ_DIA_degree, targ_APL_degree = targeted_degree_curves(G, FRACS, method="degree", mode=ATTACK_MODE)
targ_LCC_pagerank, targ_DIA_pagerank, targ_APL_pagerank = targeted_degree_curves(G, FRACS, method="pagerank", mode=ATTACK_MODE)
targ_LCC_betweenness, targ_DIA_betweenness, targ_APL_betweenness = targeted_degree_curves(G, FRACS, method="betweenness", mode=ATTACK_MODE,k_approx=k_approx_value)

R_rand = R_index(FRACS, rand_LCC)
R_targ_degree = R_index(FRACS, targ_LCC_degree)
R_targ_pagerank = R_index(FRACS, targ_LCC_pagerank)
R_targ_betweenness = R_index(FRACS, targ_LCC_betweenness)

print(f"R-index(LCC) — Random: {R_rand:.3f}")
print(f"R-index(LCC) — Targeted (Degree): {R_targ_degree:.3f}")
print(f"R-index(LCC) — Targeted (PageRank): {R_targ_pagerank:.3f}")
print(f"R-index(LCC) — Targeted (Betweenness): {R_targ_betweenness:.3f}")

# Plot LCC
plot_robustness_curves(
    "OpenFlights Robustness — LCC",
    "LCC size / N0",
    rand_LCC, targ_LCC_degree, targ_LCC_pagerank, targ_LCC_betweenness,
    "robustness_lcc.png"
)

# Plot Diameter
plot_robustness_curves(
    "OpenFlights Robustness — Diameter (approx.)",
    "Approx. Diameter of LCC (hops)",
    rand_DIA, targ_DIA_degree, targ_DIA_pagerank, targ_DIA_betweenness,
    "robustness_diameter.png"
)

# Plot Average Path Length
plot_robustness_curves(
    "OpenFlights Robustness — Average Path Length (approx.)",
    "Approx. Average Path Length",
    rand_APL, targ_APL_degree, targ_APL_pagerank, targ_APL_betweenness,
    "robustness_Average_Path_Length.png"
)

"""## Kịch bản: Defense và sau đó Attack

### TITS2018
"""

!pip install scipy geopy

import networkx as nx
import numpy as np
import random
from geopy.distance import great_circle
from scipy.sparse import csr_matrix
from scipy.sparse.linalg import splu
from typing import Any, List, Tuple, Dict, Optional


# ----------------------------
# 1) Build (grounded) Laplacian factorization
# ----------------------------
def _build_grounded_laplacian_lu(G: nx.Graph, node_list: List[Any]) -> Tuple[Dict[Any,int], int, Any, Any]:
    """
    Returns:
      idx: node->0..n-1
      g: ground index
      ground_node
      LU factorization of grounded Laplacian (n-1 x n-1)
    """
    n = len(node_list)
    idx = {u:i for i,u in enumerate(node_list)}
    g = n - 1                      # choose last node as ground
    ground_node = node_list[g]

    # adjacency (unweighted conductance=1). For weighted, use weight attr as conductance.
    rows, cols, data = [], [], []
    deg = np.zeros(n, dtype=float)

    for u, v in G.edges():
        iu, iv = idx[u], idx[v]
        w = 1.0
        if iu == iv:
            continue
        # off-diagonals -w
        rows += [iu, iv]
        cols += [iv, iu]
        data += [-w, -w]
        # diagonals accumulate degree
        deg[iu] += w
        deg[iv] += w

    # add diagonals
    rows += list(range(n))
    cols += list(range(n))
    data += deg.tolist()

    L = csr_matrix((data, (rows, cols)), shape=(n, n))

    # grounded Laplacian: remove row/col g -> SPD if connected
    mask = np.ones(n, dtype=bool)
    mask[g] = False
    Lg = L[mask][:, mask].tocsc()

    lu = splu(Lg)  # sparse LU; works well for n~few thousands
    return idx, g, ground_node, lu


def effective_resistance(lu, idx: Dict[Any,int], g: int, u: Any, v: Any) -> float:
    """
    Exact effective resistance for unweighted graph using one Laplacian solve:
      Solve L x = e_u - e_v with x_ground=0 (grounding removes singularity).
      R_eff(u,v) = (e_u - e_v)^T x = x[u] - x[v]
    """
    n = len(idx)
    iu, iv = idx[u], idx[v]

    # build b (n-1)
    b = np.zeros(n-1, dtype=float)

    def red(i):
        # map full index -> reduced index (skip ground g)
        return i if i < g else i - 1

    if iu != g:
        b[red(iu)] += 1.0
    if iv != g:
        b[red(iv)] -= 1.0

    x = lu.solve(b)  # reduced solution

    def x_full(i):
        if i == g:
            return 0.0
        return x[red(i)]

    return float(x_full(iu) - x_full(iv))


# ----------------------------
# 2) Candidate generation (random sampling + distance filter)
# ----------------------------
def geo_dist_km(G: nx.Graph, u: Any, v: Any) -> Optional[float]:
    nu, nv = G.nodes[u], G.nodes[v]
    if ("lat" in nu and "lon" in nu and "lat" in nv and "lon" in nv):
        try:
            return float(great_circle((nu["lat"], nu["lon"]), (nv["lat"], nv["lon"])).kilometers)
        except Exception:
            return None
    return None


def sample_candidate_edges(
    G: nx.Graph,
    max_candidates: int = 20000,
    max_distance_km: Optional[float] = 3000.0,
    seed: int = 0
) -> List[Tuple[Any, Any, Optional[float]]]:
    """
    Randomly sample non-edges as candidates, filtered by distance if coords exist.
    """
    rng = random.Random(seed)
    nodes = list(G.nodes())
    n = len(nodes)
    existing = set((u, v) if u <= v else (v, u) for u, v in G.edges())

    candidates = []
    tries = 0
    max_tries = max_candidates * 50  # avoid infinite loop

    while len(candidates) < max_candidates and tries < max_tries:
        tries += 1
        u = nodes[rng.randrange(n)]
        v = nodes[rng.randrange(n)]
        if u == v:
            continue
        a, b = (u, v) if u <= v else (v, u)
        if (a, b) in existing:
            continue

        d = geo_dist_km(G, u, v)
        if max_distance_km is not None and d is not None and d > max_distance_km:
            continue

        candidates.append((u, v, d))
        existing.add((a, b))  # prevent duplicates in candidate list too

    return candidates


# ----------------------------
# 3) Select k edges by highest effective resistance (TER-inspired heuristic)
# ----------------------------
def add_edges_by_effective_resistance(
    G: nx.Graph,
    k: int = 200,
    max_candidates: int = 20000,
    max_distance_km: Optional[float] = 3000.0,
    seed: int = 0
) -> Tuple[nx.Graph, List[Tuple[Any, Any, Dict[str, Any]]]]:
    """
    Build candidate edges, compute R_eff(u,v), add top-k.
    """
    if G.number_of_nodes() < 2:
        return G.copy(), []

    # work on LCC only (recommended)
    lcc = max(nx.connected_components(G), key=len)
    H = G.subgraph(lcc).copy()

    node_list = list(H.nodes())
    idx, g, ground_node, lu = _build_grounded_laplacian_lu(H, node_list)

    cand = sample_candidate_edges(H, max_candidates=max_candidates,
                                  max_distance_km=max_distance_km, seed=seed)

    scored = []
    for u, v, d in cand:
        reff = effective_resistance(lu, idx, g, u, v)
        scored.append((reff, u, v, d))

    scored.sort(reverse=True, key=lambda x: x[0])

    Hr = H.copy()
    added = []
    for reff, u, v, d in scored[:k]:
        meta = {"defense": "TER_like", "Reff": float(reff)}
        if d is not None:
            meta["distance_km"] = float(d)
        Hr.add_edge(u, v, **meta)
        added.append((u, v, meta))

    return Hr, added
import networkx as nx
import numpy as np
import random
from geopy.distance import great_circle
from scipy.sparse import csr_matrix
from scipy.sparse.linalg import splu
from typing import Any, List, Tuple, Dict, Optional


# ----------------------------
# 1) Build (grounded) Laplacian factorization
# ----------------------------
def _build_grounded_laplacian_lu(G: nx.Graph, node_list: List[Any]) -> Tuple[Dict[Any,int], int, Any, Any]:
    """
    Returns:
      idx: node->0..n-1
      g: ground index
      ground_node
      LU factorization of grounded Laplacian (n-1 x n-1)
    """
    n = len(node_list)
    idx = {u:i for i,u in enumerate(node_list)}
    g = n - 1                      # choose last node as ground
    ground_node = node_list[g]

    # adjacency (unweighted conductance=1). For weighted, use weight attr as conductance.
    rows, cols, data = [], [], []
    deg = np.zeros(n, dtype=float)

    for u, v in G.edges():
        iu, iv = idx[u], idx[v]
        w = 1.0
        if iu == iv:
            continue
        # off-diagonals -w
        rows += [iu, iv]
        cols += [iv, iu]
        data += [-w, -w]
        # diagonals accumulate degree
        deg[iu] += w
        deg[iv] += w

    # add diagonals
    rows += list(range(n))
    cols += list(range(n))
    data += deg.tolist()

    L = csr_matrix((data, (rows, cols)), shape=(n, n))

    # grounded Laplacian: remove row/col g -> SPD if connected
    mask = np.ones(n, dtype=bool)
    mask[g] = False
    Lg = L[mask][:, mask].tocsc()

    lu = splu(Lg)  # sparse LU; works well for n~few thousands
    return idx, g, ground_node, lu


def effective_resistance(lu, idx: Dict[Any,int], g: int, u: Any, v: Any) -> float:
    """
    Exact effective resistance for unweighted graph using one Laplacian solve:
      Solve L x = e_u - e_v with x_ground=0 (grounding removes singularity).
      R_eff(u,v) = (e_u - e_v)^T x = x[u] - x[v]
    """
    n = len(idx)
    iu, iv = idx[u], idx[v]

    # build b (n-1)
    b = np.zeros(n-1, dtype=float)

    def red(i):
        # map full index -> reduced index (skip ground g)
        return i if i < g else i - 1

    if iu != g:
        b[red(iu)] += 1.0
    if iv != g:
        b[red(iv)] -= 1.0

    x = lu.solve(b)  # reduced solution

    def x_full(i):
        if i == g:
            return 0.0
        return x[red(i)]

    return float(x_full(iu) - x_full(iv))


# ----------------------------
# 2) Candidate generation (random sampling + distance filter)
# ----------------------------
def geo_dist_km(G: nx.Graph, u: Any, v: Any) -> Optional[float]:
    nu, nv = G.nodes[u], G.nodes[v]
    if ("lat" in nu and "lon" in nu and "lat" in nv and "lon" in nv):
        try:
            return float(great_circle((nu["lat"], nu["lon"]), (nv["lat"], nv["lon"])).kilometers)
        except Exception:
            return None
    return None


def sample_candidate_edges(
    G: nx.Graph,
    max_candidates: int = 20000,
    max_distance_km: Optional[float] = 3000.0,
    seed: int = 0
) -> List[Tuple[Any, Any, Optional[float]]]:
    """
    Randomly sample non-edges as candidates, filtered by distance if coords exist.
    """
    rng = random.Random(seed)
    nodes = list(G.nodes())
    n = len(nodes)
    existing = set((u, v) if u <= v else (v, u) for u, v in G.edges())

    candidates = []
    tries = 0
    max_tries = max_candidates * 50  # avoid infinite loop

    while len(candidates) < max_candidates and tries < max_tries:
        tries += 1
        u = nodes[rng.randrange(n)]
        v = nodes[rng.randrange(n)]
        if u == v:
            continue
        a, b = (u, v) if u <= v else (v, u)
        if (a, b) in existing:
            continue

        d = geo_dist_km(G, u, v)
        if max_distance_km is not None and d is not None and d > max_distance_km:
            continue

        candidates.append((u, v, d))
        existing.add((a, b))  # prevent duplicates in candidate list too

    return candidates


# ----------------------------
# 3) Select k edges by highest effective resistance (TER-inspired heuristic)
# ----------------------------
def add_edges_by_effective_resistance(
    G: nx.Graph,
    k: int = 200,
    max_candidates: int = 20000,
    max_distance_km: Optional[float] = 3000.0,
    seed: int = 0
) -> Tuple[nx.Graph, List[Tuple[Any, Any, Dict[str, Any]]]]:
    """
    Build candidate edges, compute R_eff(u,v), add top-k.
    """
    if G.number_of_nodes() < 2:
        return G.copy(), []

    # work on LCC only (recommended)
    lcc = max(nx.connected_components(G), key=len)
    H = G.subgraph(lcc).copy()

    node_list = list(H.nodes())
    idx, g, ground_node, lu = _build_grounded_laplacian_lu(H, node_list)

    cand = sample_candidate_edges(H, max_candidates=max_candidates,
                                  max_distance_km=max_distance_km, seed=seed)

    scored = []
    for u, v, d in cand:
        reff = effective_resistance(lu, idx, g, u, v)
        scored.append((reff, u, v, d))

    scored.sort(reverse=True, key=lambda x: x[0])

    Hr = H.copy()
    added = []
    for reff, u, v, d in scored[:k]:
        meta = {"defense": "TER_like", "Reff": float(reff)}
        if d is not None:
            meta["distance_km"] = float(d)
        Hr.add_edge(u, v, **meta)
        added.append((u, v, meta))

    return Hr, added

G_def, added_edges = add_edges_by_effective_resistance(
    G,
    k=500,
    max_candidates=30000,
    max_distance_km=3000.0,
    seed=123
)
print("Added:", len(added_edges))

rand_LCC_def_ter, rand_DIA_def_ter, rand_APL_def_ter = random_removal_curves(G_def, FRACS, trials=TRIALS, seed=123)

k_approx_value_def = min(200, G_def.number_of_nodes() // 2)

targ_LCC_def_ter_degree, targ_DIA_def_ter_degree, targ_APL_def_ter_degree = targeted_degree_curves(G_def, FRACS, method="degree", mode=ATTACK_MODE)
targ_LCC_def_ter_pagerank, targ_DIA_def_ter_pagerank, targ_APL_def_ter_pagerank = targeted_degree_curves(G_def, FRACS, method="pagerank", mode=ATTACK_MODE)
targ_LCC_def_ter_betweenness, targ_DIA_def_ter_betweenness, targ_APL_def_ter_betweenness = targeted_degree_curves(G_def, FRACS, method="betweenness", mode=ATTACK_MODE, k_approx=k_approx_value_def)

R_rand_def_ter = R_index(FRACS, rand_LCC_def_ter)
R_targ_def_ter_degree = R_index(FRACS, targ_LCC_def_ter_degree)
R_targ_def_ter_pagerank = R_index(FRACS, targ_LCC_def_ter_pagerank)
R_targ_def_ter_betweenness = R_index(FRACS, targ_LCC_def_ter_betweenness)

print(f"R-index(LCC) — Random Ter: {R_rand_def_ter:.3f}")
print(f"R-index(LCC) — Targeted (Degree) Ter: {R_targ_def_ter_degree:.3f}")
print(f"R-index(LCC) — Targeted (PageRank) Ter: {R_targ_def_ter_pagerank:.3f}")
print(f"R-index(LCC) — Targeted (Betweenness) Ter: {R_targ_def_ter_betweenness:.3f}")

"""#### Plot"""

# Plot LCC after defense
plot_robustness_curves(
    "OpenFlights Robustness — LCC (TER Defense)",
    "LCC size / N0",
    rand_LCC_def_ter, targ_LCC_def_ter_degree, targ_LCC_def_ter_pagerank, targ_LCC_def_ter_betweenness,
    "robustness_lcc_def_ter.png"
)

# Plot Diameter after defense
plot_robustness_curves(
    "OpenFlights Robustness — Diameter (approx.) (TER Defense)",
    "Approx. Diameter of LCC (hops)",
    rand_DIA_def_ter, targ_DIA_def_ter_degree, targ_DIA_def_ter_pagerank, targ_DIA_def_ter_betweenness,
    "robustness_diameter_def_ter.png"
)

# Plot Average Path Length after defense
plot_robustness_curves(
    "OpenFlights Robustness — Average Path Length (approx.) (TER Defense)",
    "Approx. Average Path Length",
    rand_APL_def_ter, targ_APL_def_ter_degree, targ_APL_def_ter_pagerank, targ_APL_def_ter_betweenness,
    "robustness_Average_Path_Length_def_ter.png"
)

"""#### So sánh giữa độ bền vững của mạng gốc và mạng đã được defense"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Prepare data for comparison
comparison_data = {
    'Attack Type': ['Random', 'Targeted Degree', 'Targeted PageRank', 'Targeted Betweenness'],
    'Original': [R_rand, R_targ_degree, R_targ_pagerank, R_targ_betweenness],
    'TER Defense': [R_rand_def_ter, R_targ_def_ter_degree, R_targ_def_ter_pagerank, R_targ_def_ter_betweenness]
}
df_comparison = pd.DataFrame(comparison_data)

# Melt the DataFrame for seaborn's grouped bar plot
df_melted = df_comparison.melt(id_vars='Attack Type', var_name='Network Type', value_name='R-index (LCC)')

plt.figure(figsize=(10, 6))
sns.barplot(x='Attack Type', y='R-index (LCC)', hue='Network Type', data=df_melted, palette='coolwarm')
plt.title('Comparison of R-index (LCC): Original vs TER Defense')
plt.xlabel('Attack Type')
plt.ylabel('R-index (LCC)')
plt.ylim(0, df_melted['R-index (LCC)'].max() * 1.1) # Set y-limit to slightly above max R-index
plt.tight_layout()
plt.savefig(OUT_DIR/"r_index_comparison_original_vs_ter.png")
plt.show()
print(OUT_DIR/"r_index_comparison_original_vs_ter.png")

"""### Schneider swap edge"""

import networkx as nx
import numpy as np
import random
from typing import Any, Dict, Tuple, List, Optional


# ---------- DSU ----------
class DSU:
    __slots__ = ("p", "sz")
    def __init__(self, n: int):
        self.p = list(range(n))
        self.sz = [1] * n

    def find(self, a: int) -> int:
        p = self.p
        while p[a] != a:
            p[a] = p[p[a]]
            a = p[a]
        return a

    def union(self, a: int, b: int) -> int:
        pa, pb = self.find(a), self.find(b)
        if pa == pb:
            return self.sz[pa]
        if self.sz[pa] < self.sz[pb]:
            pa, pb = pb, pa
        self.p[pb] = pa
        self.sz[pa] += self.sz[pb]
        return self.sz[pa]


def R_index(fracs: np.ndarray, curve: np.ndarray) -> float:
    return float(np.trapz(curve, fracs))


def _static_order_by_degree(G: nx.Graph) -> List[Any]:
    deg = dict(G.degree())
    return [n for n, _ in sorted(deg.items(), key=lambda x: (-x[1], str(x[0])))]


def lcc_curve_static_dsu(G: nx.Graph, fracs: np.ndarray, order: List[Any]) -> np.ndarray:
    """
    Compute S(f)=|LCC|/N0 for static-order removal using offline add-back DSU.
    order = nodes removed from first to last (static).
    """
    node_list = list(G.nodes())
    idx = {u: i for i, u in enumerate(node_list)}
    n = len(node_list)
    if n == 0:
        return np.zeros_like(fracs, dtype=float)

    # active nodes in add-back process
    active = [False] * n
    dsu = DSU(n)
    max_cc = 0

    # lcc_size_after_k_removed[k] for k=0..n
    # k removed == n - t active, where t added back.
    lcc_after_k = np.zeros(n + 1, dtype=int)
    lcc_after_k[n] = 0

    rev = list(reversed(order))  # add back in reverse removal order
    for t, u in enumerate(rev, start=1):
        iu = idx[u]
        active[iu] = True
        # union with active neighbors
        for v in G.adj[u]:
            iv = idx[v]
            if active[iv]:
                max_cc = max(max_cc, dsu.union(iu, iv))
        max_cc = max(max_cc, 1)
        k_removed = n - t
        lcc_after_k[k_removed] = max_cc

    ks = np.clip(np.rint(fracs * n).astype(int), 0, n)
    return lcc_after_k[ks].astype(float) / float(n)


def robustness_R_static_fast(G: nx.Graph, fracs: np.ndarray, order: List[Any]) -> float:
    curve = lcc_curve_static_dsu(G, fracs, order)
    return R_index(fracs, curve)


# ---------- Schneider optimizer (fast) ----------
def optimize_schneider_fast(
    G: nx.Graph,
    fracs: Optional[np.ndarray] = None,
    max_trials: int = 20000,
    patience: int = 5000,
    min_delta_R: float = 1e-6,
    seed: int = 0,

    # prefilter strength: larger -> fewer R evaluations
    prefilter: bool = True
) -> Tuple[nx.Graph, Dict[str, Any]]:

    if fracs is None:
        fracs = np.linspace(0, 0.3, 21)

    rng = random.Random(seed)
    Gr = G.copy()

    # IMPORTANT: static order fixed because degree-preserving swaps keep degree
    order = _static_order_by_degree(Gr)
    deg = dict(Gr.degree())

    R_best = robustness_R_static_fast(Gr, fracs, order)
    edges = list(Gr.edges())

    accepted = 0
    no_improve = 0
    r_evals = 1  # already computed R_best

    def score_degree_mixing(e1, e2, ne1, ne2) -> int:
        """Lower is more onion-like: connect similar degrees."""
        (a, b), (c, d) = e1, e2
        (x1, y1), (x2, y2) = ne1, ne2
        old = abs(deg[a]-deg[b]) + abs(deg[c]-deg[d])
        new = abs(deg[x1]-deg[y1]) + abs(deg[x2]-deg[y2])
        return new - old  # negative means improved (more assortative)

    for t in range(1, max_trials + 1):
        if no_improve >= patience or Gr.number_of_edges() < 2:
            break

        e1, e2 = rng.sample(edges, 2)
        if len(set(e1 + e2)) < 4:
            no_improve += 1
            continue

        # try both swap variants, but prefilter before expensive R
        best_local = None  # (R_new, ne1, ne2)
        for ne1, ne2 in [((e1[0], e2[0]), (e1[1], e2[1])),
                         ((e1[0], e2[1]), (e1[1], e2[0]))]:

            # validity checks
            if ne1[0] == ne1[1] or ne2[0] == ne2[1]:
                continue
            if Gr.has_edge(*ne1) or Gr.has_edge(*ne2):
                continue
            if set(ne1) == set(ne2):
                continue

            if prefilter:
                # if it doesn't improve degree-mixing, skip without R eval
                if score_degree_mixing(e1, e2, ne1, ne2) >= 0:
                    continue

            # apply temporarily
            Gr.remove_edge(*e1); Gr.remove_edge(*e2)
            Gr.add_edge(*ne1); Gr.add_edge(*ne2)

            R_new = robustness_R_static_fast(Gr, fracs, order)
            r_evals += 1

            # revert
            Gr.remove_edge(*ne1); Gr.remove_edge(*ne2)
            Gr.add_edge(*e1); Gr.add_edge(*e2)

            if best_local is None or R_new > best_local[0]:
                best_local = (R_new, ne1, ne2)

        if best_local is not None and best_local[0] > R_best + min_delta_R:
            R_new, ne1, ne2 = best_local
            Gr.remove_edge(*e1); Gr.remove_edge(*e2)
            Gr.add_edge(*ne1); Gr.add_edge(*ne2)

            R_best = R_new
            accepted += 1
            no_improve = 0
            edges = list(Gr.edges())
        else:
            no_improve += 1

    info = {
        "R_best_static": float(R_best),
        "accepted_swaps": accepted,
        "trials_done": t,
        "R_evaluations": r_evals,
        "stopped_by_patience": (no_improve >= patience),
        "fracs_points": int(len(fracs)),
        "prefilter": prefilter,
    }
    return Gr, info

G_opt, info = optimize_schneider_fast(
    G,
    fracs=np.linspace(0, 0.3, 21),
    max_trials=50000,
    patience=8000,
    seed=123,
    prefilter=True
)
print(info)
rand_LCC_def_sch, rand_DIA_def_sch, rand_APL_def_sch = random_removal_curves(G_opt, FRACS, trials=TRIALS, seed=123)

k_approx_value_sch = min(200, G_opt.number_of_nodes() // 2)

targ_LCC_def_sch_degree, targ_DIA_def_sch_degree, targ_APL_def_sch_degree = targeted_degree_curves(G_opt, FRACS, method="degree", mode=ATTACK_MODE)
targ_LCC_def_sch_pagerank, targ_DIA_def_sch_pagerank, targ_APL_def_sch_pagerank = targeted_degree_curves(G_opt, FRACS, method="pagerank", mode=ATTACK_MODE)
targ_LCC_def_sch_betweenness, targ_DIA_def_sch_betweenness, targ_APL_def_sch_betweenness = targeted_degree_curves(G_opt, FRACS, method="betweenness", mode=ATTACK_MODE, k_approx=k_approx_value_sch)

R_rand_def_sch = R_index(FRACS, rand_LCC_def_sch)
R_targ_def_sch_degree = R_index(FRACS, targ_LCC_def_sch_degree)
R_targ_def_sch_pagerank = R_index(FRACS, targ_LCC_def_sch_pagerank)
R_targ_def_sch_betweenness = R_index(FRACS, targ_LCC_def_sch_betweenness)

print(f"R-index(LCC) — Random onion: {R_rand_def_sch:.3f}")
print(f"R-index(LCC) — Targeted (Degree) onion: {R_targ_def_sch_degree:.3f}")
print(f"R-index(LCC) — Targeted (PageRank) onion: {R_targ_def_sch_pagerank:.3f}")
print(f"R-index(LCC) — Targeted (Betweenness) onion: {R_targ_def_sch_betweenness:.3f}")

"""#### Plot"""

# Plot LCC after Schneider defense
plot_robustness_curves(
    "OpenFlights Robustness — LCC (Schneider Defense)",
    "LCC size / N0",
    rand_LCC_def_sch, targ_LCC_def_sch_degree, targ_LCC_def_sch_pagerank, targ_LCC_def_sch_betweenness,
    "robustness_lcc_def_sch.png"
)

# Plot Diameter after Schneider defense
plot_robustness_curves(
    "OpenFlights Robustness — Diameter (approx.) (Schneider Defense)",
    "Approx. Diameter of LCC (hops)",
    rand_DIA_def_sch, targ_DIA_def_sch_degree, targ_DIA_def_sch_pagerank, targ_DIA_def_sch_betweenness,
    "robustness_diameter_def_sch.png"
)

# Plot Average Path Length after Schneider defense
plot_robustness_curves(
    "OpenFlights Robustness — Average Path Length (approx.) (Schneider Defense)",
    "Approx. Average Path Length",
    rand_APL_def_sch, targ_APL_def_sch_degree, targ_APL_def_sch_pagerank, targ_APL_def_sch_betweenness,
    "robustness_Average_Path_Length_def_sch.png"
)

"""#### So sánh độ bền vững của mạng gốc với mạng đã được phòng thủ edge swaping"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Prepare data for comparison between Original and Schneider Defense
comparison_data_schneider = {
    'Attack Type': ['Random', 'Targeted Degree', 'Targeted PageRank', 'Targeted Betweenness'],
    'Original': [R_rand, R_targ_degree, R_targ_pagerank, R_targ_betweenness],
    'Schneider Defense': [R_rand_def_sch, R_targ_def_sch_degree, R_targ_def_sch_pagerank, R_targ_def_sch_betweenness]
}
df_comparison_schneider = pd.DataFrame(comparison_data_schneider)

# Melt the DataFrame for seaborn's grouped bar plot
df_melted_schneider = df_comparison_schneider.melt(id_vars='Attack Type', var_name='Network Type', value_name='R-index (LCC)')

plt.figure(figsize=(10, 6))
sns.barplot(x='Attack Type', y='R-index (LCC)', hue='Network Type', data=df_melted_schneider, palette='plasma')
plt.title('Comparison of R-index (LCC): Original vs Schneider Defense')
plt.xlabel('Attack Type')
plt.ylabel('R-index (LCC)')
plt.ylim(0, df_melted_schneider['R-index (LCC)'].max() * 1.1) # Set y-limit to slightly above max R-index
plt.tight_layout()
plt.savefig(OUT_DIR/"r_index_comparison_original_vs_schneider.png")
plt.show()
print(OUT_DIR/"r_index_comparison_original_vs_schneider.png")

"""## Kịch bản: Attack và sau đó Defense (sử dụng phương pháp phòng thủ của Schneider swap edge và random removal)"""

import numpy as np
import matplotlib.pyplot as plt
plt.style.use("seaborn-v0_8")

f_attack = 0.10
k_remove = int(round(f_attack * N0))

# Sắp thứ tự node theo degree giảm dần
cent_deg = compute_centrality(G, method="degree")
order_deg = [n for n,_ in sorted(cent_deg.items(),
                                 key=lambda x: (-x[1], str(x[0])))]

# Tạo G_damaged
G_damaged = G.copy()
G_damaged.remove_nodes_from(order_deg[:k_remove])

LCC_att = lcc_fraction(G_damaged, N0)
DIA_att = approx_diameter_of_LCC(G_damaged)
APL_att = approx_avg_path_of_LCC(G_damaged)

print(f"\n--- After attack (remove {f_attack*100:.1f}% top-degree nodes) ---")
print(f"Số node: {G_damaged.number_of_nodes()}, số cạnh: {G_damaged.number_of_edges()}")
print(f"LCC_att = {LCC_att:.3f}")
print(f"DIA_att = {DIA_att:.3f}")
print(f"APL_att = {APL_att:.3f}")

G_repaired, info_rep = optimize_schneider_fast(
    G_damaged,
    fracs=np.linspace(0, 0.3, 21),
    max_trials=50000,
    patience=8000,
    seed=123,
    prefilter=True
)

print("\n--- Schneider optimizer info (on damaged network) ---")
print(info_rep)
print(f"Số node sau defense: {G_repaired.number_of_nodes()}, số cạnh: {G_repaired.number_of_edges()}")

LCC_rep = lcc_fraction(G_repaired, N0)
DIA_rep = approx_diameter_of_LCC(G_repaired)
APL_rep = approx_avg_path_of_LCC(G_repaired)

print("\n--- After defense (repaired) ---")
print(f"LCC_rep = {LCC_rep:.3f}")
print(f"DIA_rep = {DIA_rep:.3f}")
print(f"APL_rep = {APL_rep:.3f}")

rand_LCC_orig, _, _ = random_removal_curves(G,          FRACS, trials=TRIALS, seed=123)
rand_LCC_dam,  _, _ = random_removal_curves(G_damaged,  FRACS, trials=TRIALS, seed=123)
rand_LCC_rep,  _, _ = random_removal_curves(G_repaired, FRACS, trials=TRIALS, seed=123)

R_rand_orig = R_index(FRACS, rand_LCC_orig)
R_rand_dam  = R_index(FRACS, rand_LCC_dam)
R_rand_rep  = R_index(FRACS, rand_LCC_rep)

print("\n--- R-index under RANDOM attack ---")
print(f"Original : {R_rand_orig:.3f}")
print(f"Damaged  : {R_rand_dam:.3f}")
print(f"Repaired : {R_rand_rep:.3f}")

plt.figure(figsize=(7,5))
plt.plot(FRACS, rand_LCC_orig, label=f"Original (R={R_rand_orig:.3f})", marker="o")
plt.plot(FRACS, rand_LCC_dam,  label=f"Damaged (R={R_rand_dam:.3f})",  marker="s")
plt.plot(FRACS, rand_LCC_rep,  label=f"Repaired (R={R_rand_rep:.3f})", marker="^")

plt.xlabel("fraction of removed nodes (f)")
plt.ylabel("LCC fraction S(f)")
plt.title("LCC(f) random attack\nOriginal vs Damaged vs Repaired")
plt.ylim(-0.05, 1.05)
plt.grid(True, alpha=0.3)
plt.legend()
plt.tight_layout()
plt.show()

labels = ["Original", "Damaged", "Repaired"]
R_vals = [R_rand_orig, R_rand_dam, R_rand_rep]

plt.figure(figsize=(6,4))
bars = plt.bar(labels, R_vals, color=["tab:green", "tab:red", "tab:blue"], alpha=0.8)
plt.ylabel("R-index (LCC, random attack)")
plt.title("Compare Robustness: before attack, after attack, after defense")

for b, r in zip(bars, R_vals):
    plt.text(b.get_x() + b.get_width()/2, b.get_height() + 0.01,
             f"{r:.3f}", ha="center", va="bottom", fontsize=9)

plt.ylim(0, max(R_vals)*1.15)
plt.tight_layout()
plt.show()

"""## Other"""

from networkx.algorithms.community import greedy_modularity_communities

# Top-15 hubs
deg = pd.Series(dict(G.degree())).sort_values(ascending=False)
top15 = deg.head(15).reset_index(); top15.columns=["airport_id","degree"]
top15 = top15.merge(ap[["airport_id","name","city","country","iata","icao"]], on="airport_id", how="left")
top15.to_csv(OUT_DIR/"top15_hubs.csv", index=False)
top15.head(10)

# 5 largest communities & their top-degree hubs
comms = list(greedy_modularity_communities(G))
deg_all = dict(G.degree())
rows = []
for cid, comm in enumerate(sorted(comms, key=lambda c: -len(c))[:5]):
    hub = max(comm, key=lambda u: deg_all[u])
    rec = ap.loc[ap["airport_id"]==hub, ["airport_id","name","city","country","iata","icao"]].iloc[0].to_dict()
    rec["community_id"] = cid
    rec["community_size"] = len(comm)
    rec["degree"] = int(deg_all[hub])
    rows.append(rec)
comm_df = pd.DataFrame(rows)
comm_df.to_csv(OUT_DIR/"top_community_hubs.csv", index=False)
comm_df

# Cross-community hub pairs without direct edges (redundancy candidates)
pairs = []
hubs = list(comm_df["airport_id"])
for i in range(len(hubs)):
    for j in range(i+1, len(hubs)):
        u, v = int(hubs[i]), int(hubs[j])
        connected = G.has_edge(u, v)
        ui = ap.loc[ap["airport_id"]==u, ["iata","city","country"]].iloc[0]
        vi = ap.loc[ap["airport_id"]==v, ["iata","city","country"]].iloc[0]
        pairs.append({"u_id":u,"u_iata":ui["iata"],"u_city":ui["city"],"u_country":ui["country"],
                      "v_id":v,"v_iata":vi["iata"],"v_city":vi["city"],"v_country":vi["country"],
                      "connected":bool(connected)})
cand = pd.DataFrame(pairs).query("connected == False")
cand.to_csv(OUT_DIR/"candidate_redundancy_pairs.csv", index=False)
cand

# per-country: nodes & edge incidents
nodes = pd.DataFrame({"airport_id": list(G.nodes())}).merge(ap[["airport_id","country"]], on="airport_id", how="left")
node_counts = nodes.groupby("country", dropna=False)["airport_id"].count().reset_index(name="num_airports")

edge_rows = []
for u, v in G.edges():
    cu = ap.loc[ap["airport_id"]==u, "country"].values[0]
    cv = ap.loc[ap["airport_id"]==v, "country"].values[0]
    edge_rows.append({"country": cu})
    edge_rows.append({"country": cv})
edge_counts = pd.DataFrame(edge_rows).groupby("country", dropna=False).size().reset_index(name="edge_incidents")

country_stats = node_counts.merge(edge_counts, on="country", how="outer").fillna(0)
country_stats = country_stats.sort_values(["edge_incidents","num_airports"], ascending=False)
country_stats.to_csv(OUT_DIR/"country_stats.csv", index=False)
country_stats.head(10)

# explode equipment tokens & map to planes
eq_list = []
for eq in r_clean["equipment"].tolist():
    if not eq: continue
    for token in str(eq).split():
        eq_list.append(token.strip().upper())
eq_df = pd.DataFrame({"equipment_token": eq_list})

if not eq_df.empty:
    pl_iata = pl.dropna(subset=["iata_code"])[["iata_code","name"]].rename(columns={"iata_code":"equipment_token","name":"plane_name_iata"})
    pl_icao = pl.dropna(subset=["icao_code"])[["icao_code","name"]].rename(columns={"icao_code":"equipment_token","name":"plane_name_icao"})

    eq_stats = eq_df.value_counts("equipment_token").reset_index(name="count")
    eq_stats = eq_stats.merge(pl_iata, on="equipment_token", how="left")
    eq_stats = eq_stats.merge(pl_icao, on="equipment_token", how="left")
    eq_stats["plane_name"] = eq_stats["plane_name_iata"].combine_first(eq_stats["plane_name_icao"])
    eq_stats["mapped"] = ~eq_stats["plane_name"].isna()
    coverage = eq_stats["mapped"].mean()
    eq_stats.to_csv(OUT_DIR/"equipment_stats.csv", index=False)
    with open(OUT_DIR/"equipment_stats_README.txt","w") as f:
        f.write(f"Equipment tokens mapped to Planes: {coverage:.2%} coverage (by unique tokens)\\n")
    eq_stats.head(15)
else:
    print("No equipment tokens found in routes.")

rt_air = rt.copy()
rt_air["airline_key"] = rt_air["airline_id"].astype("Int64").astype(str).where(rt_air["airline_id"].notna(), rt_air["airline_code"].astype(str))

src = rt_air.groupby("src_id")["airline_key"].nunique().reset_index(name="num_airlines_src")
dst = rt_air.groupby("dst_id")["airline_key"].nunique().reset_index(name="num_airlines_dst")
div = src.merge(dst, left_on="src_id", right_on="dst_id", how="outer")
div["airport_id"] = div["src_id"].fillna(div["dst_id"]).astype("Int64")
div["airline_diversity"] = div["num_airlines_src"].fillna(0) + div["num_airlines_dst"].fillna(0)

out = div.merge(ap[["airport_id","name","city","country","iata","icao"]], on="airport_id", how="left")
out = out[["airport_id","name","city","country","iata","icao","airline_diversity"]].sort_values("airline_diversity", ascending=False)
out.to_csv(OUT_DIR/"airport_airline_diversity.csv", index=False)
out.head(10)

import pandas as pd

table_data = []

for idx, (u, v, meta) in enumerate(added_edges, 1):
    # Lấy thông tin từ node attributes trong đồ thị Hr
    u_info = G_def.nodes[u]
    v_info = G_def.nodes[v]

    row = {
        "Rank": idx,
        "City A": u_info.get('city', 'Unknown'),
        "IATA A": u_info.get('iata', str(u)), # Dùng IATA cho gọn
        "City B": v_info.get('city', 'Unknown'),
        "IATA B": v_info.get('iata', str(v)),
        "Eff. Resistance": meta.get('Reff', 0),
        "Distance (km)": meta.get('distance_km', 0)
    }
    table_data.append(row)
df_added = pd.DataFrame(table_data)
print(df_added.to_markdown(index=False, floatfmt=".4f"))

"""## Case Study

## SGN -> CFN
"""

import networkx as nx
import pandas as pd
import matplotlib.pyplot as plt
from geopy.distance import great_circle

def add_distance_weights(graph, airports_df):
    """
    Tính và thêm trọng số 'weight' (khoảng cách km) cho tất cả các cạnh trong đồ thị.
    Dùng cho cả G gốc và G_def.
    """
    print(f"Calculating edge distances for graph with {graph.number_of_edges()} edges...")

    coords = airports_df.set_index("airport_id")[["lat", "lon"]].to_dict("index")

    count = 0
    for u, v, data in graph.edges(data=True):
        if "weight" in data:
            continue

        if u in coords and v in coords:
            pos_u = (coords[u]["lat"], coords[u]["lon"])
            pos_v = (coords[v]["lat"], coords[v]["lon"])
            try:
                dist_km = great_circle(pos_u, pos_v).kilometers
                data["weight"] = dist_km
            except ValueError:
                data["weight"] = 99999.0
        else:
            data["weight"] = 99999.0

        count += 1

    print(f"-> Added weights to {count} edges.")
    return graph

def analyze_flight_route(G, src_iata, dst_iata, attack_nodes_iata=None):
    # Tìm Airport ID
    try:
        src_row = ap[ap["iata"] == src_iata]
        dst_row = ap[ap["iata"] == dst_iata]
        if src_row.empty or dst_row.empty:
            print(f"Error: Invalid IATA code {src_iata} or {dst_iata}")
            return

        src_id = src_row.iloc[0]["airport_id"]
        dst_id = dst_row.iloc[0]["airport_id"]
        src_name = src_row.iloc[0]["name"]
        dst_name = dst_row.iloc[0]["name"]
    except Exception as e:
        print(f"Error looking up airports: {e}")
        return

    print(f"\n{'='*60}")
    print(f"CASE STUDY: {src_iata} ({src_name}) -> {dst_iata} ({dst_name})")
    print(f"{'='*60}")

    try:
        path = nx.shortest_path(G, source=src_id, target=dst_id, weight="weight")
        dist = nx.shortest_path_length(G, source=src_id, target=dst_id, weight="weight")

        print(f"\n[1] ORIGINAL ROUTE (Total: {dist:.2f} km)")
        route_str = [G.nodes[n].get("iata", str(n)) for n in path]
        print(f"   Route: {' -> '.join(route_str)}")
        print(f"   Hops: {len(path)-1}")

    except nx.NetworkXNoPath:
        print(f"No path found between {src_iata} and {dst_iata}")
        return

    target_ids = []
    if attack_nodes_iata:
        for code in attack_nodes_iata:
            row = ap[ap["iata"] == code]
            if not row.empty:
                target_ids.append(row.iloc[0]["airport_id"])

    if not target_ids:
        print("\n   (!) No attack targets specified.")
        return

    print(f"\n[2] ATTACK SIMULATION")
    print(f"   Removing nodes: {attack_nodes_iata}")

    G_attack = G.copy()
    G_attack.remove_nodes_from(target_ids)

    try:
        new_path = nx.shortest_path(G_attack, source=src_id, target=dst_id, weight="weight")
        new_dist = nx.shortest_path_length(G_attack, source=src_id, target=dst_id, weight="weight")

        print(f"\n[3] REROUTED PATH (Total: {new_dist:.2f} km)")
        new_route_str = [G.nodes[n].get("iata", str(n)) for n in new_path]
        print(f"   New Route: {' -> '.join(new_route_str)}")
        print(f"   Impact: +{new_dist - dist:.2f} km")

    except nx.NetworkXNoPath:
        print(f"\n[3] SYSTEM FAILURE: Network disconnected!")

def adaptive_route_attack_simulation(G, G_def, src_iata, dst_iata):
    try:
        src_id = ap[ap["iata"] == src_iata].iloc[0]["airport_id"]
        dst_id = ap[ap["iata"] == dst_iata].iloc[0]["airport_id"]
    except:
        print("Error: Mã sân bay không hợp lệ.")
        return

    print(f"\n{'='*70}")
    print(f"ADAPTIVE ATTACK SIMULATION: {src_iata} -> {dst_iata}")
    print(f"{'='*70}")

    try:
        path = nx.shortest_path(G, source=src_id, target=dst_id, weight="weight")
        transit_ids = path[1:-1]
        transit_codes = [ap[ap['airport_id']==nid].iloc[0]['iata'] for nid in transit_ids]

        print(f"Current Optimal Route: {' -> '.join([ap[ap['airport_id']==n].iloc[0]['iata'] for n in path])}")
        print(f"Critical Transit Nodes: {transit_codes}")

        if not transit_codes:
            print("(!) Đường bay thẳng. Không có transit để tấn công.")
            return
    except nx.NetworkXNoPath:
        print("Không có đường bay ban đầu.")
        return

    results_orig = []
    results_def = []
    labels = []

    # Kịch bản 0: Baseline (Không tấn công)
    d_base_orig = nx.shortest_path_length(G, src_id, dst_id, weight="weight")
    try:
        d_base_def = nx.shortest_path_length(G_def, src_id, dst_id, weight="weight")
    except: d_base_def = float('inf')

    results_orig.append(d_base_orig)
    results_def.append(d_base_def)
    labels.append("None")

    print("\n--- ATTACK RESULTS ---")
    print(f"{'Target':<10} | {'Original (km)':<15} | {'Defended (km)':<15} | {'Delta'}")
    print("-" * 60)


    for target_code, target_id in zip(transit_codes, transit_ids):
        # Tấn công G
        G_temp = G.copy()
        G_temp.remove_node(target_id)
        try: d_orig = nx.shortest_path_length(G_temp, src_id, dst_id, weight="weight")
        except: d_orig = float('inf')

        # Tấn công G_def
        G_def_temp = G_def.copy()
        G_def_temp.remove_node(target_id)
        try: d_def = nx.shortest_path_length(G_def_temp, src_id, dst_id, weight="weight")
        except: d_def = float('inf')

        results_orig.append(d_orig)
        results_def.append(d_def)
        labels.append(f"-{target_code}")

        # In kết quả
        s_orig = f"{d_orig:.1f}" if d_orig != float('inf') else "DEAD"
        s_def = f"{d_def:.1f}" if d_def != float('inf') else "DEAD"
        print(f"{target_code:<10} | {s_orig:<15} | {s_def:<15} | {d_def - d_orig if d_orig!=float('inf') and d_def!=float('inf') else '---'}")

    # Kịch bản final
    combo_targets = ['DUB', 'GLA']
    combo_ids = [ap[ap['iata']==c].iloc[0]['airport_id'] for c in combo_targets if len(ap[ap['iata']==c]) > 0]

    if combo_ids:
        # Tấn công G
        G_temp = G.copy()
        G_temp.remove_nodes_from(combo_ids)
        try: d_orig = nx.shortest_path_length(G_temp, src_id, dst_id, weight="weight")
        except: d_orig = float('inf')

        # Tấn công G_def
        G_def_temp = G_def.copy()
        G_def_temp.remove_nodes_from(combo_ids)
        try: d_def = nx.shortest_path_length(G_def_temp, src_id, dst_id, weight="weight")
        except: d_def = float('inf')

        results_orig.append(d_orig)
        results_def.append(d_def)
        labels.append("Combo")
        print(f"{'Combo':<10} | {d_orig if d_orig!=float('inf') else 'DEAD':<15} | {d_def if d_def!=float('inf') else 'DEAD':<15} | ---")

    # Vẽ biểu đồ
    max_val = max([v for v in results_orig + results_def if v != float('inf')] + [10000]) * 1.2
    plot_orig = [v if v != float('inf') else max_val for v in results_orig]
    plot_def = [v if v != float('inf') else max_val for v in results_def]

    x = range(len(labels))
    width = 0.35
    fig, ax = plt.subplots(figsize=(10, 6))
    ax.bar([i - width/2 for i in x], plot_orig, width, label='Original', color='#ff9999')
    ax.bar([i + width/2 for i in x], plot_def, width, label='Defended', color='#66b3ff')


    for i, v in enumerate(results_orig):
        if v == float('inf'): ax.text(i - width/2, max_val*0.95, 'X', ha='center', color='red', fontweight='bold', fontsize=14)
    for i, v in enumerate(results_def):
        if v == float('inf'): ax.text(i + width/2, max_val*0.95, 'X', ha='center', color='red', fontweight='bold', fontsize=14)

    ax.set_ylabel('Path Length (km)')
    ax.set_title(f'Attack Simulation: {src_iata} -> {dst_iata}')
    ax.set_xticks(x)
    ax.set_xticklabels(labels)
    ax.legend()
    plt.tight_layout()
    plt.show()


add_distance_weights(G, ap)
add_distance_weights(G_def, ap)

adaptive_route_attack_simulation(G, G_def, "SGN", "CFN")

"""# Experiement: so sánh giữa Undirected và Directed Graph khi tấn công

## Build Graph
"""

def build_directed_graph(ap, rt):
    # 1. Xác định tập node hợp lệ ban đầu từ file airports
    valid = set(ap["airport_id"])

    # 2. Lọc routes:
    # - Điểm đi (src) và đến (dst) phải nằm trong danh sách node valid
    r = rt[(rt["src_id"].isin(valid)) & (rt["dst_id"].isin(valid))]
    # - Loại bỏ self-loops (bay tại chỗ A -> A)
    r = r[r["src_id"] != r["dst_id"]].copy()

    G = nx.DiGraph()
    G.add_nodes_from(ap["airport_id"].tolist())
    G.add_edges_from(zip(r["src_id"], r["dst_id"]))

    # 4. Gán thuộc tính cho node
    attrs = ap.set_index("airport_id")[["name","city","country","iata","icao","lat","lon"]].to_dict("index")
    nx.set_node_attributes(G, attrs)

    return G, r

# --- SỬ DỤNG ---
G_di, r_clean_di = build_directed_graph(ap, rt)

print(f"Số node ban đầu (Directed): {G_di.number_of_nodes()}")
print(f"Số cạnh ban đầu (Directed): {G_di.number_of_edges()}")

largest_wcc_nodes = max(nx.weakly_connected_components(G_di), key=len)

G_di_clean = G_di.subgraph(largest_wcc_nodes).copy()

# Cập nhật lại G_di
G_di = G_di_clean
N0_di = G_di.number_of_nodes()

print(f"Số node sau khi lọc (WCC): {G_di.number_of_nodes()}")
print(f"Số cạnh sau khi lọc: {G_di.number_of_edges()}")

"""## Metrics"""

!pip install networkit

from networkx.algorithms import approximation as apx
import networkit as nk
from math import inf
import random
import networkx as nx
import numpy as np


# ========== WCC VERSIONS (for directed graph) ==========

def wcc_nodes(G):
    """Trả về tập node của WCC lớn nhất (dùng cho directed graph)"""
    if not isinstance(G, nx.DiGraph):
        raise TypeError("wcc_nodes() chỉ dùng cho DiGraph. Dùng lcc_nodes() cho Graph.")
    return max(nx.weakly_connected_components(G), key=len) if G.number_of_nodes() > 0 else set()


def wcc_fraction(G, N0):
    """Tính tỉ lệ WCC so với N0 ban đầu"""
    return (len(wcc_nodes(G))/float(N0)) if G.number_of_nodes() > 0 and N0>0 else 0.0


def approx_diameter_of_WCC(G):
    """
    Tính đường kính xấp xỉ của WCC lớn nhất.

    Lưu ý: Để tính diameter, ta chuyển WCC sang undirected vì:
    - Directed diameter rất khó tính (có thể không tồn tại đường đi giữa mọi cặp)
    - WCC về mặt connectivity = "bỏ qua hướng cạnh"
    """
    if G.number_of_nodes() == 0:
        return float("nan")

    W = G.subgraph(wcc_nodes(G)).copy()
    if W.number_of_nodes() <= 1:
        return 0.0

    # Chuyển sang undirected để tính diameter
    W_undi = W.to_undirected()

    try:
        return float(apx.diameter(W_undi))  # 2-sweep lower bound
    except Exception:
        # fallback: 90th percentile of sampled shortest paths
        nodes = list(W_undi.nodes())[:min(100, W_undi.number_of_nodes())]
        lens = []
        for s in nodes:
            lens.extend(nx.single_source_shortest_path_length(W_undi, s).values())
        return float(np.percentile(lens, 90)) if len(lens)>0 else float("nan")


def approx_avg_path_of_WCC(G, max_samples=500):
    """
    Tính average path length xấp xỉ của WCC lớn nhất.

    Tương tự diameter, ta chuyển sang undirected để tính APL
    vì trong robustness analysis ta quan tâm connectivity tổng quát.
    """
    if G.number_of_nodes() == 0:
        return float("nan")

    W = G.subgraph(wcc_nodes(G)).copy()
    n = W.number_of_nodes()
    if n <= 1:
        return 0.0

    # Chuyển sang undirected
    W_undi = W.to_undirected()

    node_list = list(W_undi.nodes())
    id_map = {node: i for i, node in enumerate(node_list)}

    # Tạo graph NetworKit (undirected)
    G_nk = nk.graph.Graph(n, weighted=False, directed=False)
    for u, v in W_undi.edges():
        G_nk.addEdge(id_map[u], id_map[v])

    # Tính all-pairs shortest paths
    apsp = nk.distance.APSP(G_nk)
    apsp.run()

    # Lấy tất cả khoảng cách hữu hạn và tính trung bình
    dists = []
    for i in range(n):
        for j in range(i+1, n):
            d = apsp.getDistance(i, j)
            if d < inf:
                dists.append(d)

    return float(np.mean(dists)) if dists else float("nan")


# ========== LCC VERSIONS (giữ nguyên cho undirected graph) ==========

def lcc_nodes(G):
    """Trả về tập node của LCC (dùng cho undirected graph)"""
    if isinstance(G, nx.DiGraph):
        raise TypeError("lcc_nodes() chỉ dùng cho Graph. Dùng wcc_nodes() cho DiGraph.")
    return max(nx.connected_components(G), key=len) if G.number_of_nodes() > 0 else set()


def lcc_fraction(G, N0):
    return (len(lcc_nodes(G))/float(N0)) if G.number_of_nodes() > 0 and N0>0 else 0.0


def approx_diameter_of_LCC(G):
    if G.number_of_nodes() == 0:
        return float("nan")
    L = G.subgraph(lcc_nodes(G)).copy()
    if L.number_of_nodes() <= 1:
        return 0.0
    try:
        return float(apx.diameter(L))
    except Exception:
        nodes = list(L.nodes())[:min(100, L.number_of_nodes())]
        lens = []
        for s in nodes:
            lens.extend(nx.single_source_shortest_path_length(L, s).values())
        return float(np.percentile(lens, 90)) if len(lens)>0 else float("nan")


def approx_avg_path_of_LCC(G, max_samples=500):
    if G.number_of_nodes() == 0:
        return float("nan")
    L = G.subgraph(lcc_nodes(G)).copy()
    n = L.number_of_nodes()
    if n <= 1:
        return 0.0
    node_list = list(L.nodes())
    id_map = {node: i for i, node in enumerate(node_list)}
    G_nk = nk.graph.Graph(n, weighted=False, directed=False)
    for u, v in L.edges():
        G_nk.addEdge(id_map[u], id_map[v])
    apsp = nk.distance.APSP(G_nk)
    apsp.run()
    dists = []
    for i in range(n):
        for j in range(i+1, n):
            d = apsp.getDistance(i, j)
            if d < inf:
                dists.append(d)
    return float(np.mean(dists)) if dists else float("nan")


# ========== R-INDEX (không đổi) ==========

def R_index(fracs, curve):
    return float(np.trapezoid(curve, fracs))

"""## Configuration Experiment"""

# Configure experiment
FRACS = np.linspace(0, 1, 51) # 0%..100%
TRIALS = 20
ATTACK_MODE = "static"

"""## Consolidated Plotting
To streamline the plotting, a new function `plot_robustness_curves` is introduced. This function takes the data for random and targeted attacks across different centrality measures (degree, PageRank, betweenness) and generates a single plot. This approach promotes code reusability and makes it easier to compare the robustness metrics.
"""

def plot_robustness_curves(title, ylabel, rand_curve, targ_degree_curve, targ_pagerank_curve, targ_betweenness_curve, filename):
    plt.figure(figsize=(8,5))
    plt.plot(FRACS*100, rand_curve, label=f"Random (trials={TRIALS})")
    plt.plot(FRACS*100, targ_degree_curve, label=f"Targeted-degree ({ATTACK_MODE})")
    plt.plot(FRACS*100, targ_pagerank_curve, label=f"Targeted-PageRank ({ATTACK_MODE})")
    plt.plot(FRACS*100, targ_betweenness_curve, label=f"Targeted-Betweenness ({ATTACK_MODE})")
    plt.xlabel("Fraction of airports removed (%)")
    plt.ylabel(ylabel)
    plt.title(title)
    plt.legend(); plt.tight_layout()
    plt.savefig(OUT_DIR/filename)
    print(OUT_DIR/filename)

"""## Attack"""

def compute_centrality_directed(G, method="degree", k_approx=None):
    """
    Computes centrality for directed graph.

    Args:
        G: NetworkX DiGraph
        method: 'degree', 'in_degree', 'out_degree', 'total_degree',
                'pagerank', or 'betweenness'
        k_approx: int (optional), number of sample nodes for approx betweenness

    Returns:
        Dictionary {node: score}
    """
    if not isinstance(G, nx.DiGraph):
        raise TypeError("compute_centrality_directed() chỉ dùng cho DiGraph")

    if method == "degree" or method == "total_degree":
        # Tổng in-degree + out-degree (total degree)
        return dict(G.degree())

    elif method == "in_degree":
        # Chỉ in-degree (số cạnh vào)
        return dict(G.in_degree())

    elif method == "out_degree":
        # Chỉ out-degree (số cạnh ra)
        return dict(G.out_degree())

    elif method == "pagerank":
        # PageRank có tính đến hướng (follow outgoing edges)
        try:
            return nx.pagerank(G, alpha=0.85)
        except nx.PowerIterationFailedConvergence:
            # Fallback về degree nếu không hội tụ
            return dict(G.degree())

    elif method == "betweenness":
        # Betweenness centrality có tính đến hướng
        if k_approx and k_approx < len(G):
            return nx.betweenness_centrality(G, k=k_approx, normalized=True)
        else:
            return nx.betweenness_centrality(G, normalized=True)

    else:
        raise ValueError(f"Unknown centrality method: {method}")

def random_removal_curves_directed(G, fracs, trials=10, seed=123):

    if not isinstance(G, nx.DiGraph):
        raise TypeError("random_removal_curves_directed() chỉ dùng cho DiGraph")

    rng = random.Random(seed)
    N0 = G.number_of_nodes()
    nodes_all = list(G.nodes())

    lcc_vals, dia_vals, apl_vals = [], [], []

    for f in fracs:
        k = int(round(f * N0))
        lcc_trial, dia_trial, apl_trial = [], [], []

        for _ in range(trials):
            nodes = nodes_all[:]
            rng.shuffle(nodes)
            H = G.copy()
            H.remove_nodes_from(nodes[:k])

            # Dùng WCC cho directed graph
            lcc_trial.append(wcc_fraction(H, N0))
            dia_trial.append(approx_diameter_of_WCC(H))
            apl_trial.append(approx_avg_path_of_WCC(H))

        lcc_vals.append(float(np.mean(lcc_trial)))
        dia_vals.append(float(np.nanmean(dia_trial)))
        apl_vals.append(float(np.nanmean(apl_trial)))

    return np.array(lcc_vals), np.array(dia_vals), np.array(apl_vals)


def targeted_degree_curves_directed(G, fracs, method="degree", mode="static", k_approx=None):
    if not isinstance(G, nx.DiGraph):
        raise TypeError("targeted_degree_curves_directed() chỉ dùng cho DiGraph")

    N0 = G.number_of_nodes()
    lcc_vals, dia_vals, apl_vals = [], [], []

    if mode == "static":
        # Tính centrality một lần dựa trên graph gốc
        cent = compute_centrality_directed(G, method=method, k_approx=k_approx)
        order = [n for n, _ in sorted(cent.items(), key=lambda x: (-x[1], str(x[0])))]

        for f in fracs:
            k = int(round(f * N0))
            H = G.copy()
            H.remove_nodes_from(order[:k])

            lcc_vals.append(wcc_fraction(H, N0))
            dia_vals.append(approx_diameter_of_WCC(H))
            apl_vals.append(approx_avg_path_of_WCC(H))

    else:  # adaptive
        print(f"--- Running ADAPTIVE {method} attack on DIRECTED graph (WCC) ---")
        H = G.copy()

        # Chuyển fracs thành số lượng node cần xóa
        targets = [int(round(f * N0)) for f in fracs]

        removed_count = 0
        current_target_idx = 0

        # Lưu kết quả cho f=0 (nếu có trong fracs)
        if targets and targets[0] == 0:
            lcc_vals.append(wcc_fraction(H, N0))
            dia_vals.append(approx_diameter_of_WCC(H))
            apl_vals.append(approx_avg_path_of_WCC(H))
            current_target_idx += 1

        while current_target_idx < len(targets) and H.number_of_nodes() > 0:
            target_k = targets[current_target_idx]

            # Xóa dần cho đến khi đạt target tiếp theo
            while removed_count < target_k and H.number_of_nodes() > 0:
                # Tính lại centrality trên đồ thị hiện tại H
                cent = compute_centrality_directed(H, method=method, k_approx=k_approx)

                if not cent:
                    break

                # Tìm node max score
                best_node = max(cent.items(), key=lambda x: (x[1], str(x[0])))[0]

                H.remove_node(best_node)
                removed_count += 1

            # Đã đạt mốc f, ghi lại kết quả
            lcc_vals.append(wcc_fraction(H, N0))
            dia_vals.append(approx_diameter_of_WCC(H))
            apl_vals.append(approx_avg_path_of_WCC(H))

            current_target_idx += 1

    return np.array(lcc_vals), np.array(dia_vals), np.array(apl_vals)

"""## Attack on Directed Graph

"""

# Random failures
rand_LCC, rand_DIA, rand_APL = random_removal_curves_directed(G_di, FRACS, trials=TRIALS, seed=123)

k_approx_value = min(200, G_di.number_of_nodes() // 2)
# Targeted attacks by degree
targ_LCC_degree, targ_DIA_degree, targ_APL_degree = targeted_degree_curves_directed(G_di, FRACS, method="degree", mode=ATTACK_MODE)
targ_LCC_pagerank, targ_DIA_pagerank, targ_APL_pagerank = targeted_degree_curves_directed(G_di, FRACS, method="pagerank", mode=ATTACK_MODE)
targ_LCC_betweenness, targ_DIA_betweenness, targ_APL_betweenness = targeted_degree_curves_directed(G_di, FRACS, method="betweenness", mode=ATTACK_MODE,k_approx=k_approx_value)

R_rand_di = R_index(FRACS, rand_LCC)
R_targ_degree_di = R_index(FRACS, targ_LCC_degree)
R_targ_pagerank_di = R_index(FRACS, targ_LCC_pagerank)
R_targ_betweenness_di = R_index(FRACS, targ_LCC_betweenness)

print(f"R-index(LCC) — Random: {R_rand:.3f}")
print(f"R-index(LCC) — Targeted (Degree): {R_targ_degree:.3f}")
print(f"R-index(LCC) — Targeted (PageRank): {R_targ_pagerank:.3f}")
print(f"R-index(LCC) — Targeted (Betweenness): {R_targ_betweenness:.3f}")

# Plot LCC
plot_robustness_curves(
    "OpenFlights Robustness — LCC",
    "LCC size / N0",
    rand_LCC, targ_LCC_degree, targ_LCC_pagerank, targ_LCC_betweenness,
    "robustness_lcc.png"
)

# Plot Diameter
plot_robustness_curves(
    "OpenFlights Robustness — Diameter (approx.)",
    "Approx. Diameter of LCC (hops)",
    rand_DIA, targ_DIA_degree, targ_DIA_pagerank, targ_DIA_betweenness,
    "robustness_diameter.png"
)

# Plot Average Path Length
plot_robustness_curves(
    "OpenFlights Robustness — Average Path Length (approx.)",
    "Approx. Average Path Length",
    rand_APL, targ_APL_degree, targ_APL_pagerank, targ_APL_betweenness,
    "robustness_Average_Path_Length.png"
)

"""### So sánh R index của Undirected vs Directed Graph"""

# Prepare data for comparison
comparison_data = {
    'Attack Type': ['Random', 'Targeted Degree', 'Targeted PageRank', 'Targeted Betweenness'],
    'Undirected Graph': [R_rand, R_targ_degree, R_targ_pagerank, R_targ_betweenness],
    'Directed Graph': [R_rand_di, R_targ_degree_di, R_targ_pagerank_di, R_targ_betweenness_di]
}
df_comparison = pd.DataFrame(comparison_data)

# Melt the DataFrame for seaborn's grouped bar plot
df_melted = df_comparison.melt(id_vars='Attack Type', var_name='Network Type', value_name='R-index (LCC)')

plt.figure(figsize=(10, 6))
sns.barplot(x='Attack Type', y='R-index (LCC)', hue='Network Type', data=df_melted, palette='coolwarm')
plt.title('Comparison of R-index (LCC): Original vs Undirected')
plt.xlabel('Attack Type')
plt.ylabel('R-index (LCC)')
plt.ylim(0, df_melted['R-index (LCC)'].max() * 1.1) # Set y-limit to slightly above max R-index
plt.tight_layout()
plt.savefig(OUT_DIR/"r_index_comparison_original_vs_directed.png")
plt.show()
print(OUT_DIR/"r_index_comparison_original_vs_directed.png")